{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54131077",
   "metadata": {},
   "source": [
    "# Test Set Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a341ae8",
   "metadata": {},
   "source": [
    "In this tutorial, we'll explore the test set generation module in Ragas to create a synthetic test set for a Retrieval-Augmented Generation (RAG)-based question-answering bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4442e631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar dependencias si es necesario\n",
    "# !pip install llama-index-readers-llamaparse ragas langchain openai python-dotenv\n",
    "import os\n",
    "import glob\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "from pathlib import Path  # <-- ¬°Importaci√≥n crucial para el error!\n",
    "from typing import List\n",
    "\n",
    "# --- LlamaParse, LangChain, Ragas Imports ---\n",
    "from llama_parse import LlamaParse\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import OpenAIEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "import openai\n",
    "from ragas.testset.graph import KnowledgeGraph\n",
    "from ragas.testset.graph import Node, NodeType\n",
    "from ragas.testset.transforms import apply_transforms\n",
    "from ragas.testset.transforms import HeadlinesExtractor, HeadlineSplitter, KeyphrasesExtractor\n",
    "from ragas.testset.persona import Persona\n",
    "from ragas.testset.synthesizers.single_hop.specific import (\n",
    "    SingleHopSpecificQuerySynthesizer,\n",
    ")\n",
    "from ragas.testset import TestsetGenerator\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddfba53",
   "metadata": {},
   "source": [
    "### Configuraci√≥n Inicial y variables de entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "796d3e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Credenciales validadas correctamente.\n"
     ]
    }
   ],
   "source": [
    "# 1. CARGA DE ENTORNO Y VALIDACI√ìN (TU C√ìDIGO)\n",
    "# ==========================================================\n",
    "nest_asyncio.apply()\n",
    "load_dotenv()\n",
    "\n",
    "# Configuraci√≥n OpenAI\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"‚ùå No se encontr√≥ OPENAI_API_KEY en el .env\")\n",
    "\n",
    "# Configuraci√≥n Qdrant\n",
    "QDRANT_URL = os.getenv(\"QDRANT_URL\")\n",
    "QDRANT_API_KEY = os.getenv(\"QDRANT_API_KEY\")\n",
    "COLLECTION_NAME = \"metabolomics_agent_db\" # Tu colecci√≥n definida\n",
    "\n",
    "if not QDRANT_URL:\n",
    "    raise ValueError(\"‚ùå No se encontr√≥ QDRANT_URL en el .env\")\n",
    "if not QDRANT_API_KEY:\n",
    "    raise ValueError(\"‚ùå No se encontr√≥ QDRANT_API_KEY en el .env\")\n",
    "\n",
    "# Configuraci√≥n LlamaCloud\n",
    "LLAMA_CLOUD_API_KEY = os.getenv(\"LLAMA_CLOUD_API_KEY\")\n",
    "if not LLAMA_CLOUD_API_KEY:\n",
    "    raise ValueError(\"‚ùå No se encontr√≥ LLAMA_CLOUD_API_KEY en el .env\")\n",
    "\n",
    "print(\"‚úÖ Credenciales validadas correctamente.\")\n",
    "\n",
    "\n",
    "# Directorio de salida: Esto crea la carpeta DENTRO de '../data/'\n",
    "MD_OUTPUT_DIR = Path(\"../data/data_md_files\") \n",
    "\n",
    "# Aplicar nest_asyncio para entornos como Jupyter/Colab/etc.\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3057fe6e",
   "metadata": {},
   "source": [
    "### Conversi√≥n de PDF a formato Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1be327",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def parsear_pdf(file_path: Path, output_dir: Path):\n",
    "    \"\"\"Parsea un solo archivo PDF a Markdown y lo guarda.\"\"\"\n",
    "    file_name = file_path.name\n",
    "    print(f\"   > ‚è≥ Procesando: {file_name}\")\n",
    "    try:\n",
    "        parser = LlamaParse(result_type=\"markdown\", language=\"en\")\n",
    "        \n",
    "        # Usando aload_data() para consistencia con tu entorno\n",
    "        documents = await parser.aload_data(str(file_path)) \n",
    "        \n",
    "        if documents:\n",
    "            output_file_path = output_dir / f\"{file_path.stem}.md\"\n",
    "            \n",
    "            # *** CORRECCI√ìN: Concatenar el texto de TODOS los documentos devueltos ***\n",
    "            markdown_content = \"\\n\\n\".join([doc.text for doc in documents])\n",
    "            \n",
    "            with open(output_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(markdown_content)\n",
    "                \n",
    "            print(f\"   > ‚úÖ Convertido (P√°ginas: {len(documents)}): {file_name} -> {output_file_path.name}\")\n",
    "        else:\n",
    "            print(f\"   > ‚ö†Ô∏è LlamaParse no pudo extraer contenido de: {file_name}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   > ‚ùå ERROR al procesar {file_name}. Detalle: {e}\")\n",
    "\n",
    "async def main_ingest():\n",
    "    \"\"\"Busca PDFs en '../data/data_files/' y coordina su conversi√≥n a Markdown.\"\"\"\n",
    "    # RUTA DE B√öSQUEDA: ../data/data_files/\n",
    "    ruta_data = os.path.join(\"..\", \"data\", \"data_files\", \"*.pdf\")\n",
    "    pdf_files = [Path(f) for f in glob.glob(ruta_data)]\n",
    "    \n",
    "    print(f\"\\nüìÇ Buscando archivos en: {ruta_data}\")\n",
    "    \n",
    "    if not pdf_files:\n",
    "        print(\"‚ùå No se encontraron PDFs en la carpeta '../data/data_files/'. Deteniendo el pipeline.\")\n",
    "        print(f\"   Directorio actual: {os.getcwd()}\")\n",
    "        return None\n",
    "\n",
    "    print(f\"‚úÖ Se encontraron {len(pdf_files)} archivos PDF: {[f.name for f in pdf_files]}\")\n",
    "\n",
    "    # Crear el directorio de salida (../data/data_md_files)\n",
    "    MD_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    print(f\"   Iniciando conversi√≥n de {len(pdf_files)} archivos (Secuencial)...\")\n",
    "    \n",
    "    # Procesamiento secuencial (estable)\n",
    "    for f in pdf_files:\n",
    "        await parsear_pdf(f, MD_OUTPUT_DIR)\n",
    "        \n",
    "    print(\"\\n‚úÖ Conversi√≥n a Markdown finalizada.\")\n",
    "    \n",
    "    return MD_OUTPUT_DIR\n",
    "\n",
    "# Ejecutar la conversi√≥n\n",
    "output_dir_path = asyncio.run(main_ingest())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c497da33",
   "metadata": {},
   "source": [
    "### Creaci√≥n de Knowledge Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dae8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not output_dir_path:\n",
    "    print(\"No se cargar√° el Test Set ya que no se encontraron documentos fuente.\")\n",
    "    exit()\n",
    "\n",
    "# Cargar documentos Markdown\n",
    "path = str(output_dir_path) \n",
    "print(f\"\\nüìÇ Cargando documentos desde: {path}\")\n",
    "# El DirectoryLoader lee el .md que LlamaParse cre√≥\n",
    "loader = DirectoryLoader(path, glob=\"**/*.md\")\n",
    "docs = loader.load()\n",
    "\n",
    "if not docs:\n",
    "    print(\"‚ùå Error de carga: No se encontraron documentos Markdown para procesar.\")\n",
    "    exit()\n",
    "else:\n",
    "    print(f\"‚úÖ Se cargaron {len(docs)} documentos.\")\n",
    "\n",
    "# Setup de LLMs y Embeddings\n",
    "# NOTA: Aseg√∫rate de que las claves de OpenAI se cargaron en la Celda 1.\n",
    "generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o-mini\"))\n",
    "openai_client = openai.OpenAI()\n",
    "generator_embeddings = OpenAIEmbeddings(client=openai_client, model=\"text-embedding-3-small\")  \n",
    "\n",
    "## Create Knowledge Graph (Grafo de Conocimiento)\n",
    "# Inicializamos el grafo con el contenido de los documentos.\n",
    "print(\"\\n‚öôÔ∏è Creando Knowledge Graph base...\")\n",
    "kg = KnowledgeGraph()\n",
    "for doc in docs:\n",
    "    kg.nodes.append(\n",
    "        Node(\n",
    "            type=NodeType.DOCUMENT,\n",
    "            properties={\"page_content\": doc.page_content, \"document_metadata\": doc.metadata}\n",
    "        )\n",
    "    )\n",
    "print(f\"   > Knowledge Graph inicial creado con {len(kg.nodes)} nodos base.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a27b6c3",
   "metadata": {},
   "source": [
    "### Configuraci√≥n de Transforms y Personas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1b2c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup the transforms\n",
    "# Aplicamos transforms para extraer titulares, dividir contenido y obtener frases clave.\n",
    "print(\"\\nüõ†Ô∏è Aplicando Transforms para enriquecer el Knowledge Graph...\")\n",
    "headline_extractor = HeadlinesExtractor(llm=generator_llm, max_num=20)\n",
    "headline_splitter = HeadlineSplitter(max_tokens=1500)\n",
    "keyphrase_extractor = KeyphrasesExtractor(llm=generator_llm)\n",
    "\n",
    "transforms = [\n",
    "    headline_extractor,\n",
    "    headline_splitter,\n",
    "    keyphrase_extractor\n",
    "]\n",
    "\n",
    "apply_transforms(kg, transforms=transforms)\n",
    "print(\"   > Transforms aplicados (Headlines, Keyphrases).\")\n",
    "\n",
    "## Configuring Personas for Query Generation (Adaptadas a Bio-Actives)\n",
    "print(\"\\nüë• Definiendo Personas para generar diversidad de consultas:\")\n",
    "\n",
    "persona_first_time_analyst = Persona(\n",
    "    name=\"First Time Analyst (Principiante)\",\n",
    "    role_description=\"Analista reci√©n integrado al lab. Necesita gu√≠a clara sobre la identificaci√≥n b√°sica de metabolitos y la interpretaci√≥n de datos LC-MS (m/z y RT).\",\n",
    ")\n",
    "\n",
    "persona_experienced_chemist = Persona(\n",
    "    name=\"Experienced Chemist (Experto)\",\n",
    "    role_description=\"Qu√≠mico con experiencia buscando detalles finos. Interesado en is√≥meros, estructuras complejas, rutas biosint√©ticas y resultados internos de estudios anteriores.\",\n",
    ")\n",
    "\n",
    "persona_bioactivity_researcher = Persona(\n",
    "    name=\"Bioactivity Researcher (Bi√≥logo)\",\n",
    "    role_description=\"Investigador enfocado en la funci√≥n. Su prioridad es conocer las actividades biol√≥gicas, los ensayos in vitro/in vivo asociados y la toxicidad potencial de un compuesto.\",\n",
    ")\n",
    "\n",
    "personas = [persona_first_time_analyst, persona_experienced_chemist, persona_bioactivity_researcher]   \n",
    "print(\"   > Personas definidas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3443d9",
   "metadata": {},
   "source": [
    "### Generaci√≥n Final del Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767327ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# --- 5.1 Configuraci√≥n de la Generaci√≥n ---\n",
    "\n",
    "## Query Generation Using Synthesizers\n",
    "# Se define la distribuci√≥n de consultas (50% titulares, 50% frases clave).\n",
    "query_distribution = [\n",
    "    (\n",
    "        SingleHopSpecificQuerySynthesizer(llm=generator_llm, property_name=\"headlines\"),\n",
    "        0.5,\n",
    "    ),\n",
    "    (\n",
    "        SingleHopSpecificQuerySynthesizer(\n",
    "            llm=generator_llm, property_name=\"keyphrases\"\n",
    "        ),\n",
    "        0.5,\n",
    "    ),\n",
    "]    \n",
    "print(\"\\nüéØ Synthesizers configurados para un mix de preguntas.\")\n",
    "\n",
    "# Inicializamos el generador con los LLMs, Embeddings, Knowledge Graph y Personas.\n",
    "generator = TestsetGenerator(\n",
    "    llm=generator_llm,\n",
    "    embedding_model=generator_embeddings,\n",
    "    knowledge_graph=kg,\n",
    "    persona_list=personas,\n",
    ")   \n",
    "\n",
    "print(\"‚úÖ Generador de Test Set inicializado. Listo para generar.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0d7ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5.2 Generaci√≥n y Guardado ---\n",
    "\n",
    "print(\"\\nüöÄ Iniciando la generaci√≥n del Test Set (10 preguntas)...\")\n",
    "\n",
    "# Ejecuci√≥n de la generaci√≥n\n",
    "testset = generator.generate(testset_size=10, query_distribution=query_distribution)\n",
    "\n",
    "print(\"\\n‚úÖ Generaci√≥n de Test Set completada.\")\n",
    "\n",
    "# --- 6. Guardar Resultados en evals/datasets/ ---\n",
    "# 1. Definir la carpeta de salida dentro de evals/\n",
    "OUTPUT_DIR = Path(\"datasets\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True) # Crea la carpeta si no existe\n",
    "\n",
    "# 2. Extraer el nombre base del documento fuente (usando el nombre del archivo de origen)\n",
    "base_filename = Path(docs[0].metadata[\"source\"]).stem\n",
    "\n",
    "# 3. Construir el nombre del archivo final\n",
    "OUTPUT_FILENAME = OUTPUT_DIR / f\"{base_filename}_testset.csv\"\n",
    "\n",
    "# Convertir a DataFrame y guardar\n",
    "testset_df = testset.to_pandas()\n",
    "testset_df.to_csv(OUTPUT_FILENAME, index=False)\n",
    "print(f\"üíæ Test Set guardado exitosamente en: {os.path.abspath(OUTPUT_FILENAME)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83933994",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2718d100",
   "metadata": {},
   "source": [
    "### Imports y Definici√≥n de Clases RAG/Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6eaef5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports para RAG y Evaluaci√≥n ---\n",
    "from typing import Any, Dict, Optional\n",
    "import os\n",
    "import asyncio\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from openai import AsyncOpenAI\n",
    "# Se asume que las librer√≠as 'langchain_classic' fueron instaladas con otras dependencias\n",
    "from langchain_classic.docstore.document import Document\n",
    "from langchain_classic.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.retrievers import BM25Retriever as LangchainBM25Retriever\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from ragas.metrics import DiscreteMetric\n",
    "from ragas import experiment\n",
    "from ragas import Dataset\n",
    "\n",
    "# --- 1. BM25 Retriever para Documentos Locales ---\n",
    "class BM25Retriever:\n",
    "    \"\"\"Retriever simple basado en BM25 para buscar en tu documento Markdown local.\"\"\"\n",
    "    \n",
    "    def __init__(self, doc_path: Path, default_k=3):\n",
    "        self.default_k = default_k\n",
    "        self.retriever = self._build_retriever(doc_path)\n",
    "    \n",
    "    def _build_retriever(self, doc_path: Path) -> LangchainBM25Retriever:\n",
    "        \"\"\"Construye un retriever BM25 a partir de un archivo Markdown local.\"\"\"\n",
    "        print(f\"Cargando documento desde: {doc_path}\")\n",
    "        \n",
    "        # Cargamos el documento Markdown\n",
    "        loader = DirectoryLoader(str(doc_path.parent), glob=doc_path.name)\n",
    "        source_documents = loader.load()\n",
    "\n",
    "        # Divisi√≥n de documentos (Chunking)\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1000,\n",
    "            chunk_overlap=100,\n",
    "            add_start_index=True,\n",
    "            strip_whitespace=True,\n",
    "            separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"],\n",
    "        )\n",
    "        \n",
    "        all_chunks = []\n",
    "        for document in source_documents:\n",
    "            chunks = text_splitter.split_documents([document])\n",
    "            all_chunks.extend(chunks)\n",
    "        \n",
    "        # Deduplicaci√≥n simple\n",
    "        unique_chunks = []\n",
    "        seen_content = set()\n",
    "        for chunk in all_chunks:\n",
    "            if chunk.page_content not in seen_content:\n",
    "                seen_content.add(chunk.page_content)\n",
    "                unique_chunks.append(chunk)\n",
    "        \n",
    "        print(f\"Creados {len(unique_chunks)} fragmentos √∫nicos para RAG.\")\n",
    "        \n",
    "        # Se asume que 'rank_bm25' ya est√° instalado aqu√≠.\n",
    "        return LangchainBM25Retriever.from_documents(\n",
    "            documents=unique_chunks,\n",
    "            k=1,\n",
    "        )\n",
    "    \n",
    "    def retrieve(self, query: str, top_k: int = None):\n",
    "        \"\"\"Recupera documentos para una consulta dada.\"\"\"\n",
    "        if top_k is None:\n",
    "            top_k = self.default_k\n",
    "        self.retriever.k = top_k\n",
    "        return self.retriever.invoke(query)\n",
    "\n",
    "# --- 2. Sistema RAG Simple ---\n",
    "class RAG:\n",
    "    \"\"\"Sistema RAG simple para recuperaci√≥n de documentos y generaci√≥n de respuestas.\"\"\"\n",
    "\n",
    "    def __init__(self, llm_client: AsyncOpenAI, retriever: BM25Retriever, system_prompt=None, model=\"gpt-4o-mini\", default_k=3):\n",
    "        self.llm_client = llm_client\n",
    "        self.retriever = retriever\n",
    "        self.model = model\n",
    "        self.default_k = default_k\n",
    "        self.system_prompt = system_prompt or \"Responde √∫nicamente bas√°ndote en los documentos proporcionados. S√© conciso.\\n\\nPregunta: {query}\\nDocumentos:\\n{context}\\nRespuesta:\"\n",
    "\n",
    "    async def query(self, question: str, top_k: Optional[int] = None) -> Dict[str, Any]:\n",
    "        \"\"\"Consulta el sistema RAG.\"\"\"\n",
    "        if top_k is None:\n",
    "            top_k = self.default_k\n",
    "\n",
    "        return await self._naive_query(question, top_k)\n",
    "\n",
    "    async def _naive_query(self, question: str, top_k: int) -> Dict[str, Any]:\n",
    "        \"\"\"Maneja el RAG ingenuo: recupera una vez, luego genera.\"\"\"\n",
    "        # 1. Recuperar documentos\n",
    "        docs = self.retriever.retrieve(question, top_k)\n",
    "\n",
    "        if not docs:\n",
    "            return {\"answer\": \"No se encontraron documentos relevantes.\", \"retrieved_documents\": [], \"num_retrieved\": 0}\n",
    "\n",
    "        # 2. Construir el contexto\n",
    "        context = \"\\n\\n\".join([f\"Documento {i}:\\n{doc.page_content}\" for i, doc in enumerate(docs, 1)])\n",
    "        prompt = self.system_prompt.format(query=question, context=context)\n",
    "\n",
    "        # 3. Generar respuesta usando OpenAI\n",
    "        response = await self.llm_client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"answer\": response.choices[0].message.content.strip(),\n",
    "            \"retrieved_documents\": [{\"content\": doc.page_content, \"metadata\": doc.metadata, \"document_id\": i} for i, doc in enumerate(docs)],\n",
    "            \"num_retrieved\": len(docs)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17355a9b",
   "metadata": {},
   "source": [
    "### Inicializaci√≥n del RAG y Carga del Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16f07800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando documento desde: ../data/data_md_files/1-s2.0-S0022316622152399-main.md\n",
      "Creados 45 fragmentos √∫nicos para RAG.\n",
      "\n",
      "‚úÖ Sistema RAG Inicializado.\n",
      "---\n",
      "‚úÖ Cargado el dataset de evaluaci√≥n con 10 muestras.\n"
     ]
    }
   ],
   "source": [
    "# Inicializaci√≥n\n",
    "# NOTA: Asume que las variables de entorno para las claves API est√°n definidas.\n",
    "\n",
    "# 1. Inicializar el Cliente Async OpenAI\n",
    "llm_client = AsyncOpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "\n",
    "# 2. Definir la ruta al archivo Markdown del usuario (dentro de data/data_md_files/)\n",
    "KNOWLEDGE_BASE_PATH = Path(\"../data/data_md_files/1-s2.0-S0022316622152399-main.md\")\n",
    "\n",
    "# 3. Construir el Retriever BM25 (Esta l√≠nea requiri√≥ 'rank_bm25')\n",
    "bm25_retriever = BM25Retriever(doc_path=KNOWLEDGE_BASE_PATH)\n",
    "\n",
    "# 4. Inicializar el Sistema RAG Simple\n",
    "rag_system = RAG(llm_client=llm_client, retriever=bm25_retriever)\n",
    "\n",
    "print(\"\\n‚úÖ Sistema RAG Inicializado.\")\n",
    "print(\"---\")\n",
    "\n",
    "# 5. Cargar el Test Set Ragas generado (desde evals/datasets/)\n",
    "TESTSET_PATH = Path(\"datasets/1-s2.0-S0022316622152399-main_testset.csv\")\n",
    "if not TESTSET_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Test set no encontrado en {TESTSET_PATH}. Aseg√∫rate de que la Celda 5.2 fue ejecutada correctamente.\")\n",
    "\n",
    "eval_df = pd.read_csv(TESTSET_PATH)\n",
    "print(f\"‚úÖ Cargado el dataset de evaluaci√≥n con {len(eval_df)} muestras.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343b940d",
   "metadata": {},
   "source": [
    "### Setup de M√©trica y Funci√≥n de Evaluaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38add228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Funci√≥n de Experimento corregida definitivamente para usar 'user_input' y 'reference'.\n"
     ]
    }
   ],
   "source": [
    "# Importaciones necesarias (asume Celda 6 ya ejecutada)\n",
    "from ragas.metrics import DiscreteMetric\n",
    "from ragas import experiment\n",
    "from ragas import Dataset\n",
    "from typing import Dict, Any\n",
    "\n",
    "# --- 1. Definir M√©trica de Correcci√≥n ---\n",
    "# La m√©trica en s√≠ misma no necesita cambios, solo las claves de acceso en la funci√≥n.\n",
    "correctness_metric = DiscreteMetric(\n",
    "    name=\"correctness\",\n",
    "    prompt=\"\"\"Compara la respuesta del modelo con la respuesta esperada y determina si es correcta.\n",
    "\n",
    "Considera la respuesta correcta si:\n",
    "1. Contiene la informaci√≥n clave de la respuesta esperada\n",
    "2. Es precisa en base al contexto proporcionado\n",
    "3. Responde adecuadamente a la pregunta\n",
    "\n",
    "Retorna 'pass' si la respuesta es correcta, 'fail' si es incorrecta.\n",
    "\n",
    "Pregunta: {question}\n",
    "Respuesta Esperada: {expected_answer}\n",
    "Respuesta del Modelo: {response}\n",
    "\n",
    "Evaluaci√≥n:\"\"\",\n",
    "    allowed_values=[\"pass\", \"fail\"],\n",
    ")\n",
    "\n",
    "# --- 2. Definir Funci√≥n de Evaluaci√≥n del Experimento (CORRECCI√ìN FINAL DEFINITIVA) ---\n",
    "@experiment()\n",
    "async def evaluate_rag(row: Dict[str, Any], rag: RAG, llm) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Ejecuta la evaluaci√≥n RAG en una sola fila del dataset.\n",
    "    \"\"\"\n",
    "    # CORRECCI√ìN FINAL: Usar los nombres de columna exactos de tu CSV\n",
    "    question = row[\"user_input\"] # <--- Columna de pregunta\n",
    "    reference_answer = row[\"reference\"] # <--- Columna de respuesta esperada\n",
    "\n",
    "    # Consultar el sistema RAG\n",
    "    rag_response = await rag.query(question, top_k=4)\n",
    "    model_response = rag_response.get(\"answer\", \"\")\n",
    "\n",
    "    # Evaluar correcci√≥n as√≠ncronamente\n",
    "    score = await correctness_metric.ascore(\n",
    "        question=question,\n",
    "        expected_answer=reference_answer, # Usamos la respuesta de la columna 'reference'\n",
    "        response=model_response,\n",
    "        llm=llm\n",
    "    )\n",
    "\n",
    "    # Devolver los resultados de la evaluaci√≥n\n",
    "    result = {\n",
    "        **row,\n",
    "        \"model_response\": model_response,\n",
    "        \"correctness_score\": score.value,\n",
    "        \"correctness_reason\": score.reason,\n",
    "        \"retrieved_documents\": [\n",
    "            doc.get(\"content\", \"\")[:200] + \"...\" if len(doc.get(\"content\", \"\")) > 200 else doc.get(\"content\", \"\")\n",
    "            for doc in rag_response.get(\"retrieved_documents\", [])\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    return result\n",
    "\n",
    "print(\"‚úÖ Funci√≥n de Experimento corregida definitivamente para usar 'user_input' y 'reference'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c715785",
   "metadata": {},
   "source": [
    "### Ejecuci√≥n del Experimento RAG Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43758b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaciones necesarias\n",
    "import asyncio\n",
    "from datetime import datetime\n",
    "from ragas.llms import llm_factory\n",
    "from ragas import Dataset\n",
    "import os\n",
    "import pandas as pd \n",
    "\n",
    "async def run_evaluation():\n",
    "    # --- 1. PREPARACI√ìN DEL DATASET LOCAL ---\n",
    "    print(\"\\n‚è≥ Convirtiendo DataFrame a formato Ragas Dataset...\")\n",
    "    \n",
    "    # Se usa eval_df (cargado del CSV local en Celda 7)\n",
    "    ragas_dataset = Dataset.from_pandas(\n",
    "        eval_df, \n",
    "        name=\"local_rag_testset\", \n",
    "        backend=\"local/csv\", \n",
    "        root_dir=\".\" \n",
    "    )\n",
    "    \n",
    "    # --- 2. INICIALIZACI√ìN DE COMPONENTES DE EVALUACI√ìN ---\n",
    "    llm_for_ragas = llm_factory('gpt-4o-mini', client=llm_client)\n",
    "\n",
    "    # --- 3. EJECUTAR EL EXPERIMENTO ---\n",
    "    exp_name = f\"{datetime.now().strftime('%Y%m%d-%H%M%S')}_naive_rag_local\"\n",
    "    print(f\"\\nüöÄ Iniciando experimento: {exp_name}\")\n",
    "    \n",
    "    # Ejecuci√≥n as√≠ncrona usando evaluate_rag.arun\n",
    "    results = await evaluate_rag.arun(\n",
    "        ragas_dataset, \n",
    "        name=exp_name,\n",
    "        rag=rag_system, \n",
    "        llm=llm_for_ragas \n",
    "    )\n",
    "\n",
    "    # --- 4. IMPRIMIR RESULTADOS ---\n",
    "    if results:\n",
    "        pass_count = sum(1 for result in results if result.get(\"correctness_score\") == \"pass\")\n",
    "        total_count = len(results)\n",
    "        pass_rate = (pass_count / total_count) * 100 if total_count > 0 else 0\n",
    "        print(f\"\\n--- Resumen de Evaluaci√≥n RAG ({exp_name}) ---\")\n",
    "        print(f\"Resultados: {pass_count}/{total_count} pasaron ({pass_rate:.1f}%)\")\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "    return results\n",
    "\n",
    "# Ejecutar la evaluaci√≥n \n",
    "evaluation_results = await run_evaluation()\n",
    "\n",
    "# Mostrar resultados detallados\n",
    "#print(\"\\nResultados detallados:\")\n",
    "#pd.DataFrame(evaluation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c141da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nResultados detallados:\")\n",
    "#pd.DataFrame(evaluation_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5e6056",
   "metadata": {},
   "source": [
    "### Implementaci√≥n del RAG Ag√©ntico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afb7fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaciones necesarias para RAG Ag√©ntico\n",
    "from typing import Any, Dict, Optional\n",
    "from openai import AsyncOpenAI \n",
    "import os\n",
    "# ATENCI√ìN: Se asume que las clases RAG, BM25Retriever ya est√°n definidas\n",
    "# ATENCI√ìN: Se asume que has instalado la librer√≠a 'agents'\n",
    "try:\n",
    "    from agents import Agent, function_tool, Runner \n",
    "except ImportError:\n",
    "    print(\"Error: El paquete 'agents' es requerido para el modo ag√©ntico.\")\n",
    "\n",
    "class ImprovedRAG(RAG):\n",
    "    \"\"\"RAG system that can operate in naive or agentic mode.\"\"\"\n",
    "\n",
    "    def __init__(self, llm_client: AsyncOpenAI, retriever: BM25Retriever, mode=\"agentic\", system_prompt=None, model=\"gpt-4o-mini\", default_k=3):\n",
    "        # MODIFICACI√ìN PUNTUAL: Cambiado gpt-5-mini a gpt-4o-mini\n",
    "        super().__init__(\n",
    "            llm_client=llm_client,\n",
    "            retriever=retriever,\n",
    "            system_prompt=system_prompt,\n",
    "            model=model,\n",
    "            default_k=default_k\n",
    "        )\n",
    "        self.mode = mode.lower()\n",
    "        self._agent = None\n",
    "        \n",
    "        if self.mode == \"agentic\":\n",
    "            self._setup_agent()\n",
    "\n",
    "    def _setup_agent(self):\n",
    "        \"\"\"Setup agent for agentic mode.\"\"\"\n",
    "        \n",
    "        @function_tool\n",
    "        def retrieve(query: str) -> str:\n",
    "            \"\"\"Search Hugging Face docs for technical info, APIs, commands, and examples.\n",
    "            Use exact terms (e.g., \"from_pretrained\", \"ESPnet upload\", \"torchrun\"). \n",
    "            Try 2-3 targeted searches: specific terms ‚Üí tool names ‚Üí alternatives.\"\"\"\n",
    "            # self.retriever.retrieve usa el BM25 cargado con tu documento\n",
    "            docs = self.retriever.retrieve(query, self.default_k)\n",
    "            if not docs:\n",
    "                return f\"No documents found for '{query}'. Try different search terms or break down the query into smaller parts.\"\n",
    "            return \"\\n\\n\".join([f\"Doc {i}: {doc.page_content}\" for i, doc in enumerate(docs, 1)])\n",
    "\n",
    "        self._agent = Agent(\n",
    "            name=\"RAG Assistant\",\n",
    "            model=self.model,\n",
    "            instructions=\"Search with exact terms first (commands, APIs, tool names). Try 2-3 different searches if needed. Only answer from retrieved documents. Preserve exact syntax and technical details.\",\n",
    "            tools=[retrieve]\n",
    "        )\n",
    "\n",
    "    async def _agentic_query(self, question: str, top_k: int) -> Dict[str, Any]:\n",
    "        \"\"\"Handle agentic mode: agent controls retrieval strategy.\"\"\"\n",
    "        \n",
    "        # Uso de la clase Runner del paquete 'agents'\n",
    "        result = await Runner.run(self._agent, input=question)\n",
    "        \n",
    "        return {\n",
    "            \"answer\": result.final_output,\n",
    "            \"retrieved_documents\": [],  # Agent handles retrieval internally\n",
    "            \"num_retrieved\": 0,         # Cannot determine exact count from agent execution\n",
    "        }\n",
    "\n",
    "    async def query(self, question: str, top_k: Optional[int] = None) -> Dict[str, Any]:\n",
    "        \"\"\"Query the RAG system.\"\"\"\n",
    "        if top_k is None:\n",
    "            top_k = self.default_k\n",
    "            \n",
    "        try:\n",
    "            if self.mode == \"naive\":\n",
    "                return await self._naive_query(question, top_k)\n",
    "            elif self.mode == \"agentic\":\n",
    "                return await self._agentic_query(question, top_k)\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown mode: {self.mode}\")\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"answer\": f\"Error: {str(e)}\", \n",
    "                \"retrieved_documents\": [], \n",
    "                \"num_retrieved\": 0,\n",
    "            }\n",
    "print(\"‚úÖ Clase ImprovedRAG (Ag√©ntica) definida.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1aeb6e",
   "metadata": {},
   "source": [
    "### Prueba R√°pida del RAG Ag√©ntico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09f3b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaciones necesarias\n",
    "from openai import AsyncOpenAI \n",
    "import os\n",
    "\n",
    "# Inicializar cliente OpenAI (asumiendo que llm_client ya existe, pero por si acaso)\n",
    "openai_client = AsyncOpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Inicializar el retriever BM25 (asumiendo que KNOWLEDGE_BASE_PATH existe de celdas previas)\n",
    "retriever = BM25Retriever(doc_path=KNOWLEDGE_BASE_PATH)\n",
    "\n",
    "# Switch to agentic mode\n",
    "rag_agentic = ImprovedRAG(openai_client, retriever, mode=\"agentic\")\n",
    "\n",
    "question = \"What architecture is the `tokenizers-linux-x64-musl` binary designed for?\"\n",
    "result = await rag_agentic.query(question)\n",
    "print(f\"Answer: {result['answer']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f60f8c",
   "metadata": {},
   "source": [
    "### Evaluaci√≥n del RAG Ag√©ntico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87ebb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaciones necesarias\n",
    "import asyncio\n",
    "from datetime import datetime\n",
    "from ragas.llms import llm_factory\n",
    "from ragas import Dataset\n",
    "import os\n",
    "import pandas as pd \n",
    "\n",
    "# La funci√≥n evaluate_rag debe estar definida en la Celda 8 (con claves 'user_input' y 'reference')\n",
    "# y la variable eval_df debe estar cargada (Celda 7)\n",
    "\n",
    "async def run_agentic_evaluation():\n",
    "    \n",
    "    # --- 1. PREPARACI√ìN DEL DATASET LOCAL (Reutilizando eval_df) ---\n",
    "    print(\"\\n‚è≥ Convirtiendo DataFrame a formato Ragas Dataset...\")\n",
    "    # Reutilizamos la l√≥gica que funcion√≥\n",
    "    ragas_dataset = Dataset.from_pandas(\n",
    "        eval_df, \n",
    "        name=\"local_agentic_testset\", \n",
    "        backend=\"local/csv\", \n",
    "        root_dir=\".\" \n",
    "    )\n",
    "    \n",
    "    # --- 2. INICIALIZACI√ìN DE COMPONENTES DE EVALUACI√ìN ---\n",
    "    openai_client = AsyncOpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "    retriever = BM25Retriever(doc_path=KNOWLEDGE_BASE_PATH)\n",
    "    \n",
    "    # Inicializar RAG Ag√©ntico (MODIFICACI√ìN PUNTUAL: modelo a gpt-4o-mini)\n",
    "    rag = ImprovedRAG(llm_client=openai_client, retriever=retriever, model=\"gpt-4o-mini\", mode=\"agentic\")\n",
    "    \n",
    "    # Inicializar LLM para la evaluaci√≥n de Ragas\n",
    "    llm = llm_factory('gpt-4o-mini', client=openai_client)\n",
    "\n",
    "    # --- 3. EJECUTAR EL EXPERIMENTO ---\n",
    "    exp_name = f\"{datetime.now().strftime('%Y%m%d-%H%M%S')}_agentic_rag\"\n",
    "    print(f\"\\nüöÄ Iniciando experimento Ag√©ntico: {exp_name}\")\n",
    "    \n",
    "    # Ejecuci√≥n de la evaluaci√≥n\n",
    "    results = await evaluate_rag.arun(\n",
    "        ragas_dataset, \n",
    "        name=exp_name,\n",
    "        rag=rag,\n",
    "        llm=llm\n",
    "    )\n",
    "\n",
    "    # --- 4. IMPRIMIR RESULTADOS ---\n",
    "    if results:\n",
    "        pass_count = sum(1 for result in results if result.get(\"correctness_score\") == \"pass\")\n",
    "        total_count = len(results)\n",
    "        pass_rate = (pass_count / total_count) * 100 if total_count > 0 else 0\n",
    "        print(f\"\\n--- Resumen de Evaluaci√≥n RAG Ag√©ntico ({exp_name}) ---\")\n",
    "        print(f\"Resultados: {pass_count}/{total_count} pasaron ({pass_rate:.1f}%)\")\n",
    "        print(\"-\" * 55)\n",
    "\n",
    "    return results\n",
    "\n",
    "# Ejecutar la evaluaci√≥n ag√©ntica\n",
    "results_agentic = await run_agentic_evaluation()\n",
    "\n",
    "# Mostrar resultados detallados\n",
    "#print(\"\\nResultados detallados:\")\n",
    "#pd.DataFrame(results_agentic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d8bbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar resultados detallados\n",
    "print(\"\\nResultados detallados:\")\n",
    "pd.DataFrame(results_agentic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe8bbb0",
   "metadata": {},
   "source": [
    "### Prueba con Qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05dbf4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ Inicializando Embeddings y conectando a Qdrant Cloud (Nativo)...\n",
      "‚úÖ QdrantClient nativo inicializado.\n",
      "‚úÖ RAG System con Qdrant Nativo (rag_vector) conectado e inicializado.\n"
     ]
    }
   ],
   "source": [
    "# --- Imports necesarios ---\n",
    "from qdrant_client import QdrantClient # Necesario para el cliente nativo\n",
    "from langchain_community.embeddings import OpenAIEmbeddings # Necesario para generar el vector de la query\n",
    "from openai import AsyncOpenAI\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# --- Variables de Conexi√≥n (Asumidas) ---\n",
    "# Aseg√∫rate de que estas variables est√©n definidas\n",
    "QDRANT_URL = os.getenv(\"QDRANT_URL\") \n",
    "QDRANT_API_KEY = os.getenv(\"QDRANT_API_KEY\")\n",
    "COLLECTION_NAME = \"anthocyanins_test_collection\" # Reemplaza con el nombre de tu colecci√≥n\n",
    "\n",
    "\n",
    "# --- 1. Implementaci√≥n del Retriever Vectorial (Qdrant Nativo) ---\n",
    "class QdrantVectorRetriever(object):\n",
    "    \"\"\"\n",
    "    Retriever que usa el cliente nativo de Qdrant (client.search) para la recuperaci√≥n\n",
    "    vectorial. Implementa el m√©todo .retrieve() que la clase RAG espera.\n",
    "    \"\"\"\n",
    "    def __init__(self, qdrant_client: QdrantClient, embeddings_model: OpenAIEmbeddings, collection_name: str, k: int = 3):\n",
    "        self.client = qdrant_client\n",
    "        self.embeddings_model = embeddings_model\n",
    "        self.collection_name = collection_name\n",
    "        self.default_k = k\n",
    "\n",
    "    # Este m√©todo es el que llama la clase RAG base\n",
    "    def retrieve(self, query: str, top_k: int = None) -> List[Dict[str, Any]]:\n",
    "        k = top_k if top_k is not None else self.default_k\n",
    "        \n",
    "        if self.client is None:\n",
    "             raise ConnectionError(\"Qdrant client not initialized.\")\n",
    "\n",
    "        # 1. Convertir la consulta de texto a vector\n",
    "        query_vector = self.embeddings_model.embed_query(query)\n",
    "        \n",
    "        # 2. Realizar la b√∫squeda nativa en Qdrant (Punto de falla que requiere la actualizaci√≥n de la librer√≠a)\n",
    "        search_result = self.client.search(\n",
    "            collection_name=self.collection_name,\n",
    "            query_vector=query_vector,\n",
    "            limit=k,\n",
    "            with_payload=True \n",
    "        )\n",
    "        \n",
    "        # 3. Convertir el resultado al formato compatible con la clase RAG\n",
    "        rag_docs = []\n",
    "        for hit in search_result:\n",
    "            # Asumimos que el contenido del chunk se llama 'page_content' en el payload\n",
    "            page_content = hit.payload.get(\"page_content\") or hit.payload.get(\"text\", \"\") \n",
    "            \n",
    "            rag_docs.append({\n",
    "                \"page_content\": page_content, \n",
    "                \"content\": page_content, \n",
    "                \"metadata\": hit.payload\n",
    "            })\n",
    "            \n",
    "        return rag_docs\n",
    "\n",
    "# --- 2. Inicializar la Conexi√≥n y el Retriever ---\n",
    "print(\"‚è≥ Inicializando Embeddings y conectando a Qdrant Cloud (Nativo)...\")\n",
    "\n",
    "openai_client = AsyncOpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=os.getenv(\"OPENAI_API_KEY\")) \n",
    "\n",
    "try:\n",
    "    # Intenta inicializar el cliente nativo (Aqu√≠ ocurre el error si la versi√≥n es incorrecta)\n",
    "    qdrant_client = QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY)\n",
    "    print(\"‚úÖ QdrantClient nativo inicializado.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al inicializar QdrantClient. Revisa tus variables. Error: {e}\")\n",
    "    qdrant_client = None\n",
    "\n",
    "if qdrant_client:\n",
    "    # Inicializar el retriever vectorial nativo\n",
    "    qdrant_vector_retriever = QdrantVectorRetriever(\n",
    "        qdrant_client=qdrant_client,\n",
    "        embeddings_model=embeddings,\n",
    "        collection_name=COLLECTION_NAME, \n",
    "        k=3\n",
    "    )\n",
    "    \n",
    "    # --- 3. Inicializar el RAG System con el Retriever Vectorial ---\n",
    "    # La clase RAG base acepta cualquier objeto con el m√©todo .retrieve()\n",
    "    rag_vector = RAG(\n",
    "        llm_client=openai_client, \n",
    "        retriever=qdrant_vector_retriever, # <--- ¬°Nuevo Retriever Qdrant!\n",
    "        model=\"gpt-4o-mini\"\n",
    "    )\n",
    "\n",
    "    print(f\"‚úÖ RAG System con Qdrant Nativo (rag_vector) conectado e inicializado.\")\n",
    "else:\n",
    "    rag_vector = None\n",
    "    print(\"‚ùå No se pudo inicializar RAG Vectorial. Verifica las variables de Qdrant.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75eb9455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è≥ Reutilizando DataFrame para formato Ragas Dataset...\n",
      "\n",
      "üöÄ Iniciando experimento Vectorial (Qdrant Nativo): 20251127-173345_vectorrag_qdrant_fixed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running experiment: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:04<00:00,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Task failed with error: 'QdrantClient' object has no attribute 'search'\n",
      "Warning: Task failed with error: 'QdrantClient' object has no attribute 'search'\n",
      "Warning: Task failed with error: 'QdrantClient' object has no attribute 'search'\n",
      "Warning: Task failed with error: 'QdrantClient' object has no attribute 'search'\n",
      "Warning: Task failed with error: 'QdrantClient' object has no attribute 'search'\n",
      "Warning: Task failed with error: 'QdrantClient' object has no attribute 'search'\n",
      "Warning: Task failed with error: 'QdrantClient' object has no attribute 'search'\n",
      "Warning: Task failed with error: 'QdrantClient' object has no attribute 'search'\n",
      "Warning: Task failed with error: 'QdrantClient' object has no attribute 'search'\n",
      "Warning: Task failed with error: 'QdrantClient' object has no attribute 'search'\n",
      "\n",
      "Resultados detallados de RAG Vectorial (Qdrant Nativo):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importaciones necesarias\n",
    "import asyncio\n",
    "from datetime import datetime\n",
    "from ragas.llms import llm_factory\n",
    "from ragas import Dataset\n",
    "import os\n",
    "import pandas as pd \n",
    "\n",
    "async def run_vector_evaluation():\n",
    "    \n",
    "    if rag_vector is None:\n",
    "        print(\"Error: rag_vector no est√° inicializado. Ejecuta la Celda 13 y verifica las variables de Qdrant.\")\n",
    "        return None\n",
    "\n",
    "    # --- 1. PREPARACI√ìN DEL DATASET LOCAL (Reutilizando eval_df) ---\n",
    "    print(\"\\n‚è≥ Reutilizando DataFrame para formato Ragas Dataset...\")\n",
    "    ragas_dataset = Dataset.from_pandas(\n",
    "        eval_df, \n",
    "        name=\"local_vector_testset\", \n",
    "        backend=\"local/csv\", \n",
    "        root_dir=\".\" \n",
    "    )\n",
    "    \n",
    "    # --- 2. INICIALIZACI√ìN DE COMPONENTES DE EVALUACI√ìN ---\n",
    "    openai_client = AsyncOpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "    llm_for_ragas = llm_factory('gpt-4o-mini', client=openai_client)\n",
    "\n",
    "    # --- 3. EJECUTAR EL EXPERIMENTO ---\n",
    "    exp_name = f\"{datetime.now().strftime('%Y%m%d-%H%M%S')}_vectorrag_qdrant_fixed\"\n",
    "    print(f\"\\nüöÄ Iniciando experimento Vectorial (Qdrant Nativo): {exp_name}\")\n",
    "    \n",
    "    # Ejecuci√≥n de la evaluaci√≥n, usando rag_vector\n",
    "    results = await evaluate_rag.arun(\n",
    "        ragas_dataset, \n",
    "        name=exp_name,\n",
    "        rag=rag_vector, # <--- Usamos el RAG basado en embeddings (Qdrant Nativo)\n",
    "        llm=llm_for_ragas\n",
    "    )\n",
    "\n",
    "    # --- 4. IMPRIMIR RESULTADOS ---\n",
    "    if results:\n",
    "        pass_count = sum(1 for result in results if result.get(\"correctness_score\") == \"pass\")\n",
    "        total_count = len(results)\n",
    "        pass_rate = (pass_count / total_count) * 100 if total_count > 0 else 0\n",
    "        \n",
    "        print(f\"\\n--- Resumen de Evaluaci√≥n RAG Vectorial ({exp_name}) ---\")\n",
    "        print(f\"Resultados: {pass_count}/{total_count} pasaron ({pass_rate:.1f}%)\")\n",
    "        print(f\"\\nComparaci√≥n:\")\n",
    "        print(f\"  RAG Na√Øve (BM25): 50.0%\")\n",
    "        print(f\"  RAG Ag√©ntico (BM25): 50.0%\")\n",
    "        print(f\"  RAG Vectorial (Qdrant Nativo): {pass_rate:.1f}%\")\n",
    "        print(\"-\" * 55)\n",
    "\n",
    "    return results\n",
    "\n",
    "# Ejecutar la evaluaci√≥n vectorial\n",
    "results_vector = await run_vector_evaluation()\n",
    "\n",
    "# Mostrar resultados detallados\n",
    "print(\"\\nResultados detallados de RAG Vectorial (Qdrant Nativo):\")\n",
    "pd.DataFrame(results_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abd41c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
