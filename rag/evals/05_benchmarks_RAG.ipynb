{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54131077",
   "metadata": {},
   "source": [
    "# Test Set Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a341ae8",
   "metadata": {},
   "source": [
    "In this tutorial, we'll explore the test set generation module in Ragas to create a synthetic test set for a Retrieval-Augmented Generation (RAG)-based question-answering bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4442e631",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/uc_chile/proyecto_aplicado_1/rag/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Instalar dependencias si es necesario\n",
    "# !pip install llama-index-readers-llamaparse ragas langchain openai python-dotenv\n",
    "import os\n",
    "import glob\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "from pathlib import Path  # <-- ¬°Importaci√≥n crucial para el error!\n",
    "from typing import List\n",
    "\n",
    "# --- LlamaParse, LangChain, Ragas Imports ---\n",
    "from llama_parse import LlamaParse\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import OpenAIEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "import openai\n",
    "from ragas.testset.graph import KnowledgeGraph\n",
    "from ragas.testset.graph import Node, NodeType\n",
    "from ragas.testset.transforms import apply_transforms\n",
    "from ragas.testset.transforms import HeadlinesExtractor, HeadlineSplitter, KeyphrasesExtractor\n",
    "from ragas.testset.persona import Persona\n",
    "from ragas.testset.synthesizers.single_hop.specific import (\n",
    "    SingleHopSpecificQuerySynthesizer,\n",
    ")\n",
    "from ragas.testset import TestsetGenerator\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "796d3e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Credenciales validadas correctamente.\n"
     ]
    }
   ],
   "source": [
    "# 1. CARGA DE ENTORNO Y VALIDACI√ìN (TU C√ìDIGO)\n",
    "# ==========================================================\n",
    "nest_asyncio.apply()\n",
    "load_dotenv()\n",
    "\n",
    "# Configuraci√≥n OpenAI\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"‚ùå No se encontr√≥ OPENAI_API_KEY en el .env\")\n",
    "\n",
    "# Configuraci√≥n Qdrant\n",
    "QDRANT_URL = os.getenv(\"QDRANT_URL\")\n",
    "QDRANT_API_KEY = os.getenv(\"QDRANT_API_KEY\")\n",
    "COLLECTION_NAME = \"metabolomics_agent_db\" # Tu colecci√≥n definida\n",
    "\n",
    "if not QDRANT_URL:\n",
    "    raise ValueError(\"‚ùå No se encontr√≥ QDRANT_URL en el .env\")\n",
    "if not QDRANT_API_KEY:\n",
    "    raise ValueError(\"‚ùå No se encontr√≥ QDRANT_API_KEY en el .env\")\n",
    "\n",
    "# Configuraci√≥n LlamaCloud\n",
    "LLAMA_CLOUD_API_KEY = os.getenv(\"LLAMA_CLOUD_API_KEY\")\n",
    "if not LLAMA_CLOUD_API_KEY:\n",
    "    raise ValueError(\"‚ùå No se encontr√≥ LLAMA_CLOUD_API_KEY en el .env\")\n",
    "\n",
    "print(\"‚úÖ Credenciales validadas correctamente.\")\n",
    "\n",
    "\n",
    "# Directorio de salida: Esto crea la carpeta DENTRO de '../data/'\n",
    "MD_OUTPUT_DIR = Path(\"../data/data_md_files\") \n",
    "\n",
    "# Aplicar nest_asyncio para entornos como Jupyter/Colab/etc.\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab1be327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Buscando archivos en: ../data/data_files/*.pdf\n",
      "‚úÖ Se encontraron 1 archivos PDF: ['1-s2.0-S0022316622152399-main.pdf']\n",
      "   Iniciando conversi√≥n de 1 archivos (Secuencial)...\n",
      "   > ‚è≥ Procesando: 1-s2.0-S0022316622152399-main.pdf\n",
      "Started parsing the file under job_id 03440fdb-ad42-4f34-8cc0-e706a7725357\n",
      "   > ‚úÖ Convertido (P√°ginas: 7): 1-s2.0-S0022316622152399-main.pdf -> 1-s2.0-S0022316622152399-main.md\n",
      "\n",
      "‚úÖ Conversi√≥n a Markdown finalizada.\n"
     ]
    }
   ],
   "source": [
    "async def parsear_pdf(file_path: Path, output_dir: Path):\n",
    "    \"\"\"Parsea un solo archivo PDF a Markdown y lo guarda.\"\"\"\n",
    "    file_name = file_path.name\n",
    "    print(f\"   > ‚è≥ Procesando: {file_name}\")\n",
    "    try:\n",
    "        parser = LlamaParse(result_type=\"markdown\", language=\"en\")\n",
    "        \n",
    "        # Usando aload_data() para consistencia con tu entorno\n",
    "        documents = await parser.aload_data(str(file_path)) \n",
    "        \n",
    "        if documents:\n",
    "            output_file_path = output_dir / f\"{file_path.stem}.md\"\n",
    "            \n",
    "            # *** CORRECCI√ìN: Concatenar el texto de TODOS los documentos devueltos ***\n",
    "            markdown_content = \"\\n\\n\".join([doc.text for doc in documents])\n",
    "            \n",
    "            with open(output_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(markdown_content)\n",
    "                \n",
    "            print(f\"   > ‚úÖ Convertido (P√°ginas: {len(documents)}): {file_name} -> {output_file_path.name}\")\n",
    "        else:\n",
    "            print(f\"   > ‚ö†Ô∏è LlamaParse no pudo extraer contenido de: {file_name}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   > ‚ùå ERROR al procesar {file_name}. Detalle: {e}\")\n",
    "\n",
    "async def main_ingest():\n",
    "    \"\"\"Busca PDFs en '../data/data_files/' y coordina su conversi√≥n a Markdown.\"\"\"\n",
    "    # RUTA DE B√öSQUEDA: ../data/data_files/\n",
    "    ruta_data = os.path.join(\"..\", \"data\", \"data_files\", \"*.pdf\")\n",
    "    pdf_files = [Path(f) for f in glob.glob(ruta_data)]\n",
    "    \n",
    "    print(f\"\\nüìÇ Buscando archivos en: {ruta_data}\")\n",
    "    \n",
    "    if not pdf_files:\n",
    "        print(\"‚ùå No se encontraron PDFs en la carpeta '../data/data_files/'. Deteniendo el pipeline.\")\n",
    "        print(f\"   Directorio actual: {os.getcwd()}\")\n",
    "        return None\n",
    "\n",
    "    print(f\"‚úÖ Se encontraron {len(pdf_files)} archivos PDF: {[f.name for f in pdf_files]}\")\n",
    "\n",
    "    # Crear el directorio de salida (../data/data_md_files)\n",
    "    MD_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    print(f\"   Iniciando conversi√≥n de {len(pdf_files)} archivos (Secuencial)...\")\n",
    "    \n",
    "    # Procesamiento secuencial (estable)\n",
    "    for f in pdf_files:\n",
    "        await parsear_pdf(f, MD_OUTPUT_DIR)\n",
    "        \n",
    "    print(\"\\n‚úÖ Conversi√≥n a Markdown finalizada.\")\n",
    "    \n",
    "    return MD_OUTPUT_DIR\n",
    "\n",
    "# Ejecutar la conversi√≥n\n",
    "output_dir_path = asyncio.run(main_ingest())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1dae8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Cargando documentos desde: ../data/data_md_files\n",
      "‚úÖ Se cargaron 1 documentos.\n",
      "\n",
      "‚öôÔ∏è Creando Knowledge Graph base...\n",
      "   > Knowledge Graph inicial creado con 1 nodos base.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10294/1072707839.py:20: DeprecationWarning: LangchainLLMWrapper is deprecated and will be removed in a future version. Use llm_factory instead: from openai import OpenAI; from ragas.llms import llm_factory; llm = llm_factory('gpt-4o-mini', client=OpenAI(api_key='...'))\n",
      "  generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o-mini\"))\n"
     ]
    }
   ],
   "source": [
    "if not output_dir_path:\n",
    "    print(\"No se cargar√° el Test Set ya que no se encontraron documentos fuente.\")\n",
    "    exit()\n",
    "\n",
    "# Cargar documentos Markdown\n",
    "path = str(output_dir_path) \n",
    "print(f\"\\nüìÇ Cargando documentos desde: {path}\")\n",
    "# El DirectoryLoader lee el .md que LlamaParse cre√≥\n",
    "loader = DirectoryLoader(path, glob=\"**/*.md\")\n",
    "docs = loader.load()\n",
    "\n",
    "if not docs:\n",
    "    print(\"‚ùå Error de carga: No se encontraron documentos Markdown para procesar.\")\n",
    "    exit()\n",
    "else:\n",
    "    print(f\"‚úÖ Se cargaron {len(docs)} documentos.\")\n",
    "\n",
    "# Setup de LLMs y Embeddings\n",
    "# NOTA: Aseg√∫rate de que las claves de OpenAI se cargaron en la Celda 1.\n",
    "generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o-mini\"))\n",
    "openai_client = openai.OpenAI()\n",
    "generator_embeddings = OpenAIEmbeddings(client=openai_client, model=\"text-embedding-3-small\")  \n",
    "\n",
    "## Create Knowledge Graph (Grafo de Conocimiento)\n",
    "# Inicializamos el grafo con el contenido de los documentos.\n",
    "print(\"\\n‚öôÔ∏è Creando Knowledge Graph base...\")\n",
    "kg = KnowledgeGraph()\n",
    "for doc in docs:\n",
    "    kg.nodes.append(\n",
    "        Node(\n",
    "            type=NodeType.DOCUMENT,\n",
    "            properties={\"page_content\": doc.page_content, \"document_metadata\": doc.metadata}\n",
    "        )\n",
    "    )\n",
    "print(f\"   > Knowledge Graph inicial creado con {len(kg.nodes)} nodos base.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa1b2c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üõ†Ô∏è Aplicando Transforms para enriquecer el Knowledge Graph...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying HeadlinesExtractor: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.72s/it]\n",
      "Applying HeadlineSplitter: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:02<00:00,  2.49s/it]\n",
      "Applying KeyphrasesExtractor: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:15<00:00,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   > Transforms aplicados (Headlines, Keyphrases).\n",
      "\n",
      "üë• Definiendo Personas para generar diversidad de consultas:\n",
      "   > Personas definidas.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Setup the transforms\n",
    "# Aplicamos transforms para extraer titulares, dividir contenido y obtener frases clave.\n",
    "print(\"\\nüõ†Ô∏è Aplicando Transforms para enriquecer el Knowledge Graph...\")\n",
    "headline_extractor = HeadlinesExtractor(llm=generator_llm, max_num=20)\n",
    "headline_splitter = HeadlineSplitter(max_tokens=1500)\n",
    "keyphrase_extractor = KeyphrasesExtractor(llm=generator_llm)\n",
    "\n",
    "transforms = [\n",
    "    headline_extractor,\n",
    "    headline_splitter,\n",
    "    keyphrase_extractor\n",
    "]\n",
    "\n",
    "apply_transforms(kg, transforms=transforms)\n",
    "print(\"   > Transforms aplicados (Headlines, Keyphrases).\")\n",
    "\n",
    "## Configuring Personas for Query Generation (Adaptadas a Bio-Actives)\n",
    "print(\"\\nüë• Definiendo Personas para generar diversidad de consultas:\")\n",
    "\n",
    "persona_first_time_analyst = Persona(\n",
    "    name=\"First Time Analyst (Principiante)\",\n",
    "    role_description=\"Analista reci√©n integrado al lab. Necesita gu√≠a clara sobre la identificaci√≥n b√°sica de metabolitos y la interpretaci√≥n de datos LC-MS (m/z y RT).\",\n",
    ")\n",
    "\n",
    "persona_experienced_chemist = Persona(\n",
    "    name=\"Experienced Chemist (Experto)\",\n",
    "    role_description=\"Qu√≠mico con experiencia buscando detalles finos. Interesado en is√≥meros, estructuras complejas, rutas biosint√©ticas y resultados internos de estudios anteriores.\",\n",
    ")\n",
    "\n",
    "persona_bioactivity_researcher = Persona(\n",
    "    name=\"Bioactivity Researcher (Bi√≥logo)\",\n",
    "    role_description=\"Investigador enfocado en la funci√≥n. Su prioridad es conocer las actividades biol√≥gicas, los ensayos in vitro/in vivo asociados y la toxicidad potencial de un compuesto.\",\n",
    ")\n",
    "\n",
    "personas = [persona_first_time_analyst, persona_experienced_chemist, persona_bioactivity_researcher]   \n",
    "print(\"   > Personas definidas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "767327ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ Synthesizers configurados para un mix de preguntas.\n",
      "‚úÖ Generador de Test Set inicializado. Listo para generar.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# --- 5.1 Configuraci√≥n de la Generaci√≥n ---\n",
    "\n",
    "## Query Generation Using Synthesizers\n",
    "# Se define la distribuci√≥n de consultas (50% titulares, 50% frases clave).\n",
    "query_distribution = [\n",
    "    (\n",
    "        SingleHopSpecificQuerySynthesizer(llm=generator_llm, property_name=\"headlines\"),\n",
    "        0.5,\n",
    "    ),\n",
    "    (\n",
    "        SingleHopSpecificQuerySynthesizer(\n",
    "            llm=generator_llm, property_name=\"keyphrases\"\n",
    "        ),\n",
    "        0.5,\n",
    "    ),\n",
    "]    \n",
    "print(\"\\nüéØ Synthesizers configurados para un mix de preguntas.\")\n",
    "\n",
    "# Inicializamos el generador con los LLMs, Embeddings, Knowledge Graph y Personas.\n",
    "generator = TestsetGenerator(\n",
    "    llm=generator_llm,\n",
    "    embedding_model=generator_embeddings,\n",
    "    knowledge_graph=kg,\n",
    "    persona_list=personas,\n",
    ")   \n",
    "\n",
    "print(\"‚úÖ Generador de Test Set inicializado. Listo para generar.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e0d7ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Iniciando la generaci√≥n del Test Set (10 preguntas)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Scenarios: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:19<00:00,  9.73s/it]\n",
      "Generating Samples: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:10<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Generaci√≥n de Test Set completada.\n",
      "üíæ Test Set guardado exitosamente en: /home/david/uc_chile/proyecto_aplicado_1/rag/evals/datasets/1-s2.0-S0022316622152399-main_testset.csv\n"
     ]
    }
   ],
   "source": [
    "# --- 5.2 Generaci√≥n y Guardado ---\n",
    "\n",
    "print(\"\\nüöÄ Iniciando la generaci√≥n del Test Set (10 preguntas)...\")\n",
    "\n",
    "# Ejecuci√≥n de la generaci√≥n\n",
    "testset = generator.generate(testset_size=10, query_distribution=query_distribution)\n",
    "\n",
    "print(\"\\n‚úÖ Generaci√≥n de Test Set completada.\")\n",
    "\n",
    "# --- 6. Guardar Resultados en evals/datasets/ ---\n",
    "# 1. Definir la carpeta de salida dentro de evals/\n",
    "OUTPUT_DIR = Path(\"datasets\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True) # Crea la carpeta si no existe\n",
    "\n",
    "# 2. Extraer el nombre base del documento fuente (usando el nombre del archivo de origen)\n",
    "base_filename = Path(docs[0].metadata[\"source\"]).stem\n",
    "\n",
    "# 3. Construir el nombre del archivo final\n",
    "OUTPUT_FILENAME = OUTPUT_DIR / f\"{base_filename}_testset.csv\"\n",
    "\n",
    "# Convertir a DataFrame y guardar\n",
    "testset_df = testset.to_pandas()\n",
    "testset_df.to_csv(OUTPUT_FILENAME, index=False)\n",
    "print(f\"üíæ Test Set guardado exitosamente en: {os.path.abspath(OUTPUT_FILENAME)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83933994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference</th>\n",
       "      <th>persona_name</th>\n",
       "      <th>query_style</th>\n",
       "      <th>query_length</th>\n",
       "      <th>synthesizer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the significance of sample preparation...</td>\n",
       "      <td>[Human Nutrition and Metabolism\\n\\nAbsorption ...</td>\n",
       "      <td>Sample preparation is crucial in the study of ...</td>\n",
       "      <td>Bioactivity Researcher (Bi√≥logo)</td>\n",
       "      <td>PERFECT_GRAMMAR</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How do chemicals and materials play a role in ...</td>\n",
       "      <td>[Human Nutrition and Metabolism\\n\\nAbsorption ...</td>\n",
       "      <td>In the study, chemicals and materials such as ...</td>\n",
       "      <td>First Time Analyst (Principiante)</td>\n",
       "      <td>PERFECT_GRAMMAR</td>\n",
       "      <td>LONG</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is Blueberry study about?</td>\n",
       "      <td>[Human Nutrition and Metabolism\\n\\nAbsorption ...</td>\n",
       "      <td>The Blueberry study investigates the absorptio...</td>\n",
       "      <td>First Time Analyst (Principiante)</td>\n",
       "      <td>POOR_GRAMMAR</td>\n",
       "      <td>SHORT</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wht is the absorption and metabolism of anthoc...</td>\n",
       "      <td>[Human Nutrition and Metabolism\\n\\nAbsorption ...</td>\n",
       "      <td>The absorption and metabolism of anthocyanins ...</td>\n",
       "      <td>Experienced Chemist (Experto)</td>\n",
       "      <td>MISSPELLED</td>\n",
       "      <td>LONG</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are the key components of the MATERIALS A...</td>\n",
       "      <td>[Human Nutrition and Metabolism\\n\\nAbsorption ...</td>\n",
       "      <td>The MATERIALS AND METHODS section details the ...</td>\n",
       "      <td>Bioactivity Researcher (Bi√≥logo)</td>\n",
       "      <td>WEB_SEARCH_LIKE</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What is the focus of the study on anthocyanins...</td>\n",
       "      <td>[Human Nutrition and Metabolism\\n\\n Absorption...</td>\n",
       "      <td>The study focuses on the absorption and metabo...</td>\n",
       "      <td>Experienced Chemist (Experto)</td>\n",
       "      <td>WEB_SEARCH_LIKE</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What happen with elderberry extract in study?</td>\n",
       "      <td>[ABSTRACT\\n\\nThe absorption and metabolism of ...</td>\n",
       "      <td>In the study, four elderly women were given 12...</td>\n",
       "      <td>Bioactivity Researcher (Bi√≥logo)</td>\n",
       "      <td>POOR_GRAMMAR</td>\n",
       "      <td>SHORT</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How do the antioxidant capacities of anthocyan...</td>\n",
       "      <td>[KEY WORDS:\\n\\nanthocyanin\\n\\nmetabolite\\n\\nel...</td>\n",
       "      <td>The antioxidant capacities of anthocyanins (AC...</td>\n",
       "      <td>First Time Analyst (Principiante)</td>\n",
       "      <td>PERFECT_GRAMMAR</td>\n",
       "      <td>LONG</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Que es peonidin y de donde viene en los metodo...</td>\n",
       "      <td>[MATERIALS AND METHODS\\n\\n Chemicals and mater...</td>\n",
       "      <td>Peonidin es uno de los seis compuestos que se ...</td>\n",
       "      <td>First Time Analyst (Principiante)</td>\n",
       "      <td>POOR_GRAMMAR</td>\n",
       "      <td>LONG</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What was the dosage of elderberry extract cons...</td>\n",
       "      <td>[Subjects and study design. The study protocol...</td>\n",
       "      <td>The study participants consumed 12 g of elderb...</td>\n",
       "      <td>Bioactivity Researcher (Bi√≥logo)</td>\n",
       "      <td>PERFECT_GRAMMAR</td>\n",
       "      <td>SHORT</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_input  \\\n",
       "0  What is the significance of sample preparation...   \n",
       "1  How do chemicals and materials play a role in ...   \n",
       "2                     What is Blueberry study about?   \n",
       "3  Wht is the absorption and metabolism of anthoc...   \n",
       "4  What are the key components of the MATERIALS A...   \n",
       "5  What is the focus of the study on anthocyanins...   \n",
       "6      What happen with elderberry extract in study?   \n",
       "7  How do the antioxidant capacities of anthocyan...   \n",
       "8  Que es peonidin y de donde viene en los metodo...   \n",
       "9  What was the dosage of elderberry extract cons...   \n",
       "\n",
       "                                  reference_contexts  \\\n",
       "0  [Human Nutrition and Metabolism\\n\\nAbsorption ...   \n",
       "1  [Human Nutrition and Metabolism\\n\\nAbsorption ...   \n",
       "2  [Human Nutrition and Metabolism\\n\\nAbsorption ...   \n",
       "3  [Human Nutrition and Metabolism\\n\\nAbsorption ...   \n",
       "4  [Human Nutrition and Metabolism\\n\\nAbsorption ...   \n",
       "5  [Human Nutrition and Metabolism\\n\\n Absorption...   \n",
       "6  [ABSTRACT\\n\\nThe absorption and metabolism of ...   \n",
       "7  [KEY WORDS:\\n\\nanthocyanin\\n\\nmetabolite\\n\\nel...   \n",
       "8  [MATERIALS AND METHODS\\n\\n Chemicals and mater...   \n",
       "9  [Subjects and study design. The study protocol...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  Sample preparation is crucial in the study of ...   \n",
       "1  In the study, chemicals and materials such as ...   \n",
       "2  The Blueberry study investigates the absorptio...   \n",
       "3  The absorption and metabolism of anthocyanins ...   \n",
       "4  The MATERIALS AND METHODS section details the ...   \n",
       "5  The study focuses on the absorption and metabo...   \n",
       "6  In the study, four elderly women were given 12...   \n",
       "7  The antioxidant capacities of anthocyanins (AC...   \n",
       "8  Peonidin es uno de los seis compuestos que se ...   \n",
       "9  The study participants consumed 12 g of elderb...   \n",
       "\n",
       "                        persona_name      query_style query_length  \\\n",
       "0   Bioactivity Researcher (Bi√≥logo)  PERFECT_GRAMMAR       MEDIUM   \n",
       "1  First Time Analyst (Principiante)  PERFECT_GRAMMAR         LONG   \n",
       "2  First Time Analyst (Principiante)     POOR_GRAMMAR        SHORT   \n",
       "3      Experienced Chemist (Experto)       MISSPELLED         LONG   \n",
       "4   Bioactivity Researcher (Bi√≥logo)  WEB_SEARCH_LIKE       MEDIUM   \n",
       "5      Experienced Chemist (Experto)  WEB_SEARCH_LIKE       MEDIUM   \n",
       "6   Bioactivity Researcher (Bi√≥logo)     POOR_GRAMMAR        SHORT   \n",
       "7  First Time Analyst (Principiante)  PERFECT_GRAMMAR         LONG   \n",
       "8  First Time Analyst (Principiante)     POOR_GRAMMAR         LONG   \n",
       "9   Bioactivity Researcher (Bi√≥logo)  PERFECT_GRAMMAR        SHORT   \n",
       "\n",
       "                        synthesizer_name  \n",
       "0  single_hop_specific_query_synthesizer  \n",
       "1  single_hop_specific_query_synthesizer  \n",
       "2  single_hop_specific_query_synthesizer  \n",
       "3  single_hop_specific_query_synthesizer  \n",
       "4  single_hop_specific_query_synthesizer  \n",
       "5  single_hop_specific_query_synthesizer  \n",
       "6  single_hop_specific_query_synthesizer  \n",
       "7  single_hop_specific_query_synthesizer  \n",
       "8  single_hop_specific_query_synthesizer  \n",
       "9  single_hop_specific_query_synthesizer  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2718d100",
   "metadata": {},
   "source": [
    "### Imports y Definici√≥n de Clases RAG/Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6eaef5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports para RAG y Evaluaci√≥n ---\n",
    "from typing import Any, Dict, Optional\n",
    "import os\n",
    "import asyncio\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from openai import AsyncOpenAI\n",
    "# Se asume que las librer√≠as 'langchain_classic' fueron instaladas con otras dependencias\n",
    "from langchain_classic.docstore.document import Document\n",
    "from langchain_classic.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.retrievers import BM25Retriever as LangchainBM25Retriever\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from ragas.metrics import DiscreteMetric\n",
    "from ragas import experiment\n",
    "from ragas import Dataset\n",
    "\n",
    "# --- 1. BM25 Retriever para Documentos Locales ---\n",
    "class BM25Retriever:\n",
    "    \"\"\"Retriever simple basado en BM25 para buscar en tu documento Markdown local.\"\"\"\n",
    "    \n",
    "    def __init__(self, doc_path: Path, default_k=3):\n",
    "        self.default_k = default_k\n",
    "        self.retriever = self._build_retriever(doc_path)\n",
    "    \n",
    "    def _build_retriever(self, doc_path: Path) -> LangchainBM25Retriever:\n",
    "        \"\"\"Construye un retriever BM25 a partir de un archivo Markdown local.\"\"\"\n",
    "        print(f\"Cargando documento desde: {doc_path}\")\n",
    "        \n",
    "        # Cargamos el documento Markdown\n",
    "        loader = DirectoryLoader(str(doc_path.parent), glob=doc_path.name)\n",
    "        source_documents = loader.load()\n",
    "\n",
    "        # Divisi√≥n de documentos (Chunking)\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1000,\n",
    "            chunk_overlap=100,\n",
    "            add_start_index=True,\n",
    "            strip_whitespace=True,\n",
    "            separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"],\n",
    "        )\n",
    "        \n",
    "        all_chunks = []\n",
    "        for document in source_documents:\n",
    "            chunks = text_splitter.split_documents([document])\n",
    "            all_chunks.extend(chunks)\n",
    "        \n",
    "        # Deduplicaci√≥n simple\n",
    "        unique_chunks = []\n",
    "        seen_content = set()\n",
    "        for chunk in all_chunks:\n",
    "            if chunk.page_content not in seen_content:\n",
    "                seen_content.add(chunk.page_content)\n",
    "                unique_chunks.append(chunk)\n",
    "        \n",
    "        print(f\"Creados {len(unique_chunks)} fragmentos √∫nicos para RAG.\")\n",
    "        \n",
    "        # Se asume que 'rank_bm25' ya est√° instalado aqu√≠.\n",
    "        return LangchainBM25Retriever.from_documents(\n",
    "            documents=unique_chunks,\n",
    "            k=1,\n",
    "        )\n",
    "    \n",
    "    def retrieve(self, query: str, top_k: int = None):\n",
    "        \"\"\"Recupera documentos para una consulta dada.\"\"\"\n",
    "        if top_k is None:\n",
    "            top_k = self.default_k\n",
    "        self.retriever.k = top_k\n",
    "        return self.retriever.invoke(query)\n",
    "\n",
    "# --- 2. Sistema RAG Simple ---\n",
    "class RAG:\n",
    "    \"\"\"Sistema RAG simple para recuperaci√≥n de documentos y generaci√≥n de respuestas.\"\"\"\n",
    "\n",
    "    def __init__(self, llm_client: AsyncOpenAI, retriever: BM25Retriever, system_prompt=None, model=\"gpt-4o-mini\", default_k=3):\n",
    "        self.llm_client = llm_client\n",
    "        self.retriever = retriever\n",
    "        self.model = model\n",
    "        self.default_k = default_k\n",
    "        self.system_prompt = system_prompt or \"Responde √∫nicamente bas√°ndote en los documentos proporcionados. S√© conciso.\\n\\nPregunta: {query}\\nDocumentos:\\n{context}\\nRespuesta:\"\n",
    "\n",
    "    async def query(self, question: str, top_k: Optional[int] = None) -> Dict[str, Any]:\n",
    "        \"\"\"Consulta el sistema RAG.\"\"\"\n",
    "        if top_k is None:\n",
    "            top_k = self.default_k\n",
    "\n",
    "        return await self._naive_query(question, top_k)\n",
    "\n",
    "    async def _naive_query(self, question: str, top_k: int) -> Dict[str, Any]:\n",
    "        \"\"\"Maneja el RAG ingenuo: recupera una vez, luego genera.\"\"\"\n",
    "        # 1. Recuperar documentos\n",
    "        docs = self.retriever.retrieve(question, top_k)\n",
    "\n",
    "        if not docs:\n",
    "            return {\"answer\": \"No se encontraron documentos relevantes.\", \"retrieved_documents\": [], \"num_retrieved\": 0}\n",
    "\n",
    "        # 2. Construir el contexto\n",
    "        context = \"\\n\\n\".join([f\"Documento {i}:\\n{doc.page_content}\" for i, doc in enumerate(docs, 1)])\n",
    "        prompt = self.system_prompt.format(query=question, context=context)\n",
    "\n",
    "        # 3. Generar respuesta usando OpenAI\n",
    "        response = await self.llm_client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"answer\": response.choices[0].message.content.strip(),\n",
    "            \"retrieved_documents\": [{\"content\": doc.page_content, \"metadata\": doc.metadata, \"document_id\": i} for i, doc in enumerate(docs)],\n",
    "            \"num_retrieved\": len(docs)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17355a9b",
   "metadata": {},
   "source": [
    "### Inicializaci√≥n del RAG y Carga del Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16f07800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando documento desde: ../data/data_md_files/1-s2.0-S0022316622152399-main.md\n",
      "Creados 45 fragmentos √∫nicos para RAG.\n",
      "\n",
      "‚úÖ Sistema RAG Inicializado.\n",
      "---\n",
      "‚úÖ Cargado el dataset de evaluaci√≥n con 10 muestras.\n"
     ]
    }
   ],
   "source": [
    "# Inicializaci√≥n\n",
    "# NOTA: Asume que las variables de entorno para las claves API est√°n definidas.\n",
    "\n",
    "# 1. Inicializar el Cliente Async OpenAI\n",
    "llm_client = AsyncOpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "\n",
    "# 2. Definir la ruta al archivo Markdown del usuario (dentro de data/data_md_files/)\n",
    "KNOWLEDGE_BASE_PATH = Path(\"../data/data_md_files/1-s2.0-S0022316622152399-main.md\")\n",
    "\n",
    "# 3. Construir el Retriever BM25 (Esta l√≠nea requiri√≥ 'rank_bm25')\n",
    "bm25_retriever = BM25Retriever(doc_path=KNOWLEDGE_BASE_PATH)\n",
    "\n",
    "# 4. Inicializar el Sistema RAG Simple\n",
    "rag_system = RAG(llm_client=llm_client, retriever=bm25_retriever)\n",
    "\n",
    "print(\"\\n‚úÖ Sistema RAG Inicializado.\")\n",
    "print(\"---\")\n",
    "\n",
    "# 5. Cargar el Test Set Ragas generado (desde evals/datasets/)\n",
    "TESTSET_PATH = Path(\"datasets/1-s2.0-S0022316622152399-main_testset.csv\")\n",
    "if not TESTSET_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Test set no encontrado en {TESTSET_PATH}. Aseg√∫rate de que la Celda 5.2 fue ejecutada correctamente.\")\n",
    "\n",
    "eval_df = pd.read_csv(TESTSET_PATH)\n",
    "print(f\"‚úÖ Cargado el dataset de evaluaci√≥n con {len(eval_df)} muestras.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343b940d",
   "metadata": {},
   "source": [
    "### Setup de M√©trica y Funci√≥n de Evaluaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "38add228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Funci√≥n de Experimento corregida definitivamente para usar 'user_input' y 'reference'.\n"
     ]
    }
   ],
   "source": [
    "# Importaciones necesarias (asume Celda 6 ya ejecutada)\n",
    "from ragas.metrics import DiscreteMetric\n",
    "from ragas import experiment\n",
    "from ragas import Dataset\n",
    "from typing import Dict, Any\n",
    "\n",
    "# --- 1. Definir M√©trica de Correcci√≥n ---\n",
    "# La m√©trica en s√≠ misma no necesita cambios, solo las claves de acceso en la funci√≥n.\n",
    "correctness_metric = DiscreteMetric(\n",
    "    name=\"correctness\",\n",
    "    prompt=\"\"\"Compara la respuesta del modelo con la respuesta esperada y determina si es correcta.\n",
    "\n",
    "Considera la respuesta correcta si:\n",
    "1. Contiene la informaci√≥n clave de la respuesta esperada\n",
    "2. Es precisa en base al contexto proporcionado\n",
    "3. Responde adecuadamente a la pregunta\n",
    "\n",
    "Retorna 'pass' si la respuesta es correcta, 'fail' si es incorrecta.\n",
    "\n",
    "Pregunta: {question}\n",
    "Respuesta Esperada: {expected_answer}\n",
    "Respuesta del Modelo: {response}\n",
    "\n",
    "Evaluaci√≥n:\"\"\",\n",
    "    allowed_values=[\"pass\", \"fail\"],\n",
    ")\n",
    "\n",
    "# --- 2. Definir Funci√≥n de Evaluaci√≥n del Experimento (CORRECCI√ìN FINAL DEFINITIVA) ---\n",
    "@experiment()\n",
    "async def evaluate_rag(row: Dict[str, Any], rag: RAG, llm) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Ejecuta la evaluaci√≥n RAG en una sola fila del dataset.\n",
    "    \"\"\"\n",
    "    # CORRECCI√ìN FINAL: Usar los nombres de columna exactos de tu CSV\n",
    "    question = row[\"user_input\"] # <--- Columna de pregunta\n",
    "    reference_answer = row[\"reference\"] # <--- Columna de respuesta esperada\n",
    "\n",
    "    # Consultar el sistema RAG\n",
    "    rag_response = await rag.query(question, top_k=4)\n",
    "    model_response = rag_response.get(\"answer\", \"\")\n",
    "\n",
    "    # Evaluar correcci√≥n as√≠ncronamente\n",
    "    score = await correctness_metric.ascore(\n",
    "        question=question,\n",
    "        expected_answer=reference_answer, # Usamos la respuesta de la columna 'reference'\n",
    "        response=model_response,\n",
    "        llm=llm\n",
    "    )\n",
    "\n",
    "    # Devolver los resultados de la evaluaci√≥n\n",
    "    result = {\n",
    "        **row,\n",
    "        \"model_response\": model_response,\n",
    "        \"correctness_score\": score.value,\n",
    "        \"correctness_reason\": score.reason,\n",
    "        \"retrieved_documents\": [\n",
    "            doc.get(\"content\", \"\")[:200] + \"...\" if len(doc.get(\"content\", \"\")) > 200 else doc.get(\"content\", \"\")\n",
    "            for doc in rag_response.get(\"retrieved_documents\", [])\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    return result\n",
    "\n",
    "print(\"‚úÖ Funci√≥n de Experimento corregida definitivamente para usar 'user_input' y 'reference'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c715785",
   "metadata": {},
   "source": [
    "### Ejecuci√≥n del Experimento RAG Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f43758b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è≥ Convirtiendo DataFrame a formato Ragas Dataset...\n",
      "\n",
      "üöÄ Iniciando experimento: 20251126-164933_naive_rag_local\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running experiment: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:11<00:00,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Resumen de Evaluaci√≥n RAG (20251126-164933_naive_rag_local) ---\n",
      "Resultados: 4/10 pasaron (40.0%)\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Importaciones necesarias\n",
    "import asyncio\n",
    "from datetime import datetime\n",
    "from ragas.llms import llm_factory\n",
    "from ragas import Dataset\n",
    "import os\n",
    "import pandas as pd \n",
    "\n",
    "async def run_evaluation():\n",
    "    # --- 1. PREPARACI√ìN DEL DATASET LOCAL ---\n",
    "    print(\"\\n‚è≥ Convirtiendo DataFrame a formato Ragas Dataset...\")\n",
    "    \n",
    "    # Se usa eval_df (cargado del CSV local en Celda 7)\n",
    "    ragas_dataset = Dataset.from_pandas(\n",
    "        eval_df, \n",
    "        name=\"local_rag_testset\", \n",
    "        backend=\"local/csv\", \n",
    "        root_dir=\".\" \n",
    "    )\n",
    "    \n",
    "    # --- 2. INICIALIZACI√ìN DE COMPONENTES DE EVALUACI√ìN ---\n",
    "    llm_for_ragas = llm_factory('gpt-4o-mini', client=llm_client)\n",
    "\n",
    "    # --- 3. EJECUTAR EL EXPERIMENTO ---\n",
    "    exp_name = f\"{datetime.now().strftime('%Y%m%d-%H%M%S')}_naive_rag_local\"\n",
    "    print(f\"\\nüöÄ Iniciando experimento: {exp_name}\")\n",
    "    \n",
    "    # Ejecuci√≥n as√≠ncrona usando evaluate_rag.arun\n",
    "    results = await evaluate_rag.arun(\n",
    "        ragas_dataset, \n",
    "        name=exp_name,\n",
    "        rag=rag_system, \n",
    "        llm=llm_for_ragas \n",
    "    )\n",
    "\n",
    "    # --- 4. IMPRIMIR RESULTADOS ---\n",
    "    if results:\n",
    "        pass_count = sum(1 for result in results if result.get(\"correctness_score\") == \"pass\")\n",
    "        total_count = len(results)\n",
    "        pass_rate = (pass_count / total_count) * 100 if total_count > 0 else 0\n",
    "        print(f\"\\n--- Resumen de Evaluaci√≥n RAG ({exp_name}) ---\")\n",
    "        print(f\"Resultados: {pass_count}/{total_count} pasaron ({pass_rate:.1f}%)\")\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "    return results\n",
    "\n",
    "# Ejecutar la evaluaci√≥n \n",
    "evaluation_results = await run_evaluation()\n",
    "\n",
    "# Mostrar resultados detallados\n",
    "#print(\"\\nResultados detallados:\")\n",
    "#pd.DataFrame(evaluation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b5c141da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados detallados:\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nResultados detallados:\")\n",
    "#pd.DataFrame(evaluation_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5e6056",
   "metadata": {},
   "source": [
    "### Implementaci√≥n del RAG Ag√©ntico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6afb7fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Clase ImprovedRAG (Ag√©ntica) definida.\n"
     ]
    }
   ],
   "source": [
    "# Importaciones necesarias para RAG Ag√©ntico\n",
    "from typing import Any, Dict, Optional\n",
    "from openai import AsyncOpenAI \n",
    "import os\n",
    "# ATENCI√ìN: Se asume que las clases RAG, BM25Retriever ya est√°n definidas\n",
    "# ATENCI√ìN: Se asume que has instalado la librer√≠a 'agents'\n",
    "try:\n",
    "    from agents import Agent, function_tool, Runner \n",
    "except ImportError:\n",
    "    print(\"Error: El paquete 'agents' es requerido para el modo ag√©ntico.\")\n",
    "\n",
    "class ImprovedRAG(RAG):\n",
    "    \"\"\"RAG system that can operate in naive or agentic mode.\"\"\"\n",
    "\n",
    "    def __init__(self, llm_client: AsyncOpenAI, retriever: BM25Retriever, mode=\"agentic\", system_prompt=None, model=\"gpt-4o-mini\", default_k=3):\n",
    "        # MODIFICACI√ìN PUNTUAL: Cambiado gpt-5-mini a gpt-4o-mini\n",
    "        super().__init__(\n",
    "            llm_client=llm_client,\n",
    "            retriever=retriever,\n",
    "            system_prompt=system_prompt,\n",
    "            model=model,\n",
    "            default_k=default_k\n",
    "        )\n",
    "        self.mode = mode.lower()\n",
    "        self._agent = None\n",
    "        \n",
    "        if self.mode == \"agentic\":\n",
    "            self._setup_agent()\n",
    "\n",
    "    def _setup_agent(self):\n",
    "        \"\"\"Setup agent for agentic mode.\"\"\"\n",
    "        \n",
    "        @function_tool\n",
    "        def retrieve(query: str) -> str:\n",
    "            \"\"\"Search Hugging Face docs for technical info, APIs, commands, and examples.\n",
    "            Use exact terms (e.g., \"from_pretrained\", \"ESPnet upload\", \"torchrun\"). \n",
    "            Try 2-3 targeted searches: specific terms ‚Üí tool names ‚Üí alternatives.\"\"\"\n",
    "            # self.retriever.retrieve usa el BM25 cargado con tu documento\n",
    "            docs = self.retriever.retrieve(query, self.default_k)\n",
    "            if not docs:\n",
    "                return f\"No documents found for '{query}'. Try different search terms or break down the query into smaller parts.\"\n",
    "            return \"\\n\\n\".join([f\"Doc {i}: {doc.page_content}\" for i, doc in enumerate(docs, 1)])\n",
    "\n",
    "        self._agent = Agent(\n",
    "            name=\"RAG Assistant\",\n",
    "            model=self.model,\n",
    "            instructions=\"Search with exact terms first (commands, APIs, tool names). Try 2-3 different searches if needed. Only answer from retrieved documents. Preserve exact syntax and technical details.\",\n",
    "            tools=[retrieve]\n",
    "        )\n",
    "\n",
    "    async def _agentic_query(self, question: str, top_k: int) -> Dict[str, Any]:\n",
    "        \"\"\"Handle agentic mode: agent controls retrieval strategy.\"\"\"\n",
    "        \n",
    "        # Uso de la clase Runner del paquete 'agents'\n",
    "        result = await Runner.run(self._agent, input=question)\n",
    "        \n",
    "        return {\n",
    "            \"answer\": result.final_output,\n",
    "            \"retrieved_documents\": [],  # Agent handles retrieval internally\n",
    "            \"num_retrieved\": 0,         # Cannot determine exact count from agent execution\n",
    "        }\n",
    "\n",
    "    async def query(self, question: str, top_k: Optional[int] = None) -> Dict[str, Any]:\n",
    "        \"\"\"Query the RAG system.\"\"\"\n",
    "        if top_k is None:\n",
    "            top_k = self.default_k\n",
    "            \n",
    "        try:\n",
    "            if self.mode == \"naive\":\n",
    "                return await self._naive_query(question, top_k)\n",
    "            elif self.mode == \"agentic\":\n",
    "                return await self._agentic_query(question, top_k)\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown mode: {self.mode}\")\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"answer\": f\"Error: {str(e)}\", \n",
    "                \"retrieved_documents\": [], \n",
    "                \"num_retrieved\": 0,\n",
    "            }\n",
    "print(\"‚úÖ Clase ImprovedRAG (Ag√©ntica) definida.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1aeb6e",
   "metadata": {},
   "source": [
    "### Prueba R√°pida del RAG Ag√©ntico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d09f3b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando documento desde: ../data/data_md_files/1-s2.0-S0022316622152399-main.md\n",
      "Creados 45 fragmentos √∫nicos para RAG.\n",
      "Answer: I couldn't find specific information on the architecture for the `tokenizers-linux-x64-musl` binary in the retrieved documents. However, based on the naming convention, it is likely designed for the x86_64 architecture (64-bit) on Linux systems that use the musl C library. If you need more details, I recommend checking the official documentation or repository related to the tokenizers library.\n"
     ]
    }
   ],
   "source": [
    "# Importaciones necesarias\n",
    "from openai import AsyncOpenAI \n",
    "import os\n",
    "\n",
    "# Inicializar cliente OpenAI (asumiendo que llm_client ya existe, pero por si acaso)\n",
    "openai_client = AsyncOpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Inicializar el retriever BM25 (asumiendo que KNOWLEDGE_BASE_PATH existe de celdas previas)\n",
    "retriever = BM25Retriever(doc_path=KNOWLEDGE_BASE_PATH)\n",
    "\n",
    "# Switch to agentic mode\n",
    "rag_agentic = ImprovedRAG(openai_client, retriever, mode=\"agentic\")\n",
    "\n",
    "question = \"What architecture is the `tokenizers-linux-x64-musl` binary designed for?\"\n",
    "result = await rag_agentic.query(question)\n",
    "print(f\"Answer: {result['answer']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f60f8c",
   "metadata": {},
   "source": [
    "### Evaluaci√≥n del RAG Ag√©ntico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e87ebb00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è≥ Convirtiendo DataFrame a formato Ragas Dataset...\n",
      "Cargando documento desde: ../data/data_md_files/1-s2.0-S0022316622152399-main.md\n",
      "Creados 45 fragmentos √∫nicos para RAG.\n",
      "\n",
      "üöÄ Iniciando experimento Ag√©ntico: 20251126-170027_agentic_rag\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running experiment: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:17<00:00,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Resumen de Evaluaci√≥n RAG Ag√©ntico (20251126-170027_agentic_rag) ---\n",
      "Resultados: 5/10 pasaron (50.0%)\n",
      "-------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Importaciones necesarias\n",
    "import asyncio\n",
    "from datetime import datetime\n",
    "from ragas.llms import llm_factory\n",
    "from ragas import Dataset\n",
    "import os\n",
    "import pandas as pd \n",
    "\n",
    "# La funci√≥n evaluate_rag debe estar definida en la Celda 8 (con claves 'user_input' y 'reference')\n",
    "# y la variable eval_df debe estar cargada (Celda 7)\n",
    "\n",
    "async def run_agentic_evaluation():\n",
    "    \n",
    "    # --- 1. PREPARACI√ìN DEL DATASET LOCAL (Reutilizando eval_df) ---\n",
    "    print(\"\\n‚è≥ Convirtiendo DataFrame a formato Ragas Dataset...\")\n",
    "    # Reutilizamos la l√≥gica que funcion√≥\n",
    "    ragas_dataset = Dataset.from_pandas(\n",
    "        eval_df, \n",
    "        name=\"local_agentic_testset\", \n",
    "        backend=\"local/csv\", \n",
    "        root_dir=\".\" \n",
    "    )\n",
    "    \n",
    "    # --- 2. INICIALIZACI√ìN DE COMPONENTES DE EVALUACI√ìN ---\n",
    "    openai_client = AsyncOpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "    retriever = BM25Retriever(doc_path=KNOWLEDGE_BASE_PATH)\n",
    "    \n",
    "    # Inicializar RAG Ag√©ntico (MODIFICACI√ìN PUNTUAL: modelo a gpt-4o-mini)\n",
    "    rag = ImprovedRAG(llm_client=openai_client, retriever=retriever, model=\"gpt-4o-mini\", mode=\"agentic\")\n",
    "    \n",
    "    # Inicializar LLM para la evaluaci√≥n de Ragas\n",
    "    llm = llm_factory('gpt-4o-mini', client=openai_client)\n",
    "\n",
    "    # --- 3. EJECUTAR EL EXPERIMENTO ---\n",
    "    exp_name = f\"{datetime.now().strftime('%Y%m%d-%H%M%S')}_agentic_rag\"\n",
    "    print(f\"\\nüöÄ Iniciando experimento Ag√©ntico: {exp_name}\")\n",
    "    \n",
    "    # Ejecuci√≥n de la evaluaci√≥n\n",
    "    results = await evaluate_rag.arun(\n",
    "        ragas_dataset, \n",
    "        name=exp_name,\n",
    "        rag=rag,\n",
    "        llm=llm\n",
    "    )\n",
    "\n",
    "    # --- 4. IMPRIMIR RESULTADOS ---\n",
    "    if results:\n",
    "        pass_count = sum(1 for result in results if result.get(\"correctness_score\") == \"pass\")\n",
    "        total_count = len(results)\n",
    "        pass_rate = (pass_count / total_count) * 100 if total_count > 0 else 0\n",
    "        print(f\"\\n--- Resumen de Evaluaci√≥n RAG Ag√©ntico ({exp_name}) ---\")\n",
    "        print(f\"Resultados: {pass_count}/{total_count} pasaron ({pass_rate:.1f}%)\")\n",
    "        print(\"-\" * 55)\n",
    "\n",
    "    return results\n",
    "\n",
    "# Ejecutar la evaluaci√≥n ag√©ntica\n",
    "results_agentic = await run_agentic_evaluation()\n",
    "\n",
    "# Mostrar resultados detallados\n",
    "#print(\"\\nResultados detallados:\")\n",
    "#pd.DataFrame(results_agentic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "72d8bbf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados detallados:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference</th>\n",
       "      <th>persona_name</th>\n",
       "      <th>query_style</th>\n",
       "      <th>query_length</th>\n",
       "      <th>synthesizer_name</th>\n",
       "      <th>model_response</th>\n",
       "      <th>correctness_score</th>\n",
       "      <th>correctness_reason</th>\n",
       "      <th>retrieved_documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is Blueberry study about?</td>\n",
       "      <td>['Human Nutrition and Metabolism\\n\\nAbsorption...</td>\n",
       "      <td>The Blueberry study investigates the absorptio...</td>\n",
       "      <td>First Time Analyst (Principiante)</td>\n",
       "      <td>POOR_GRAMMAR</td>\n",
       "      <td>SHORT</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "      <td>The Blueberry study refers to a research proje...</td>\n",
       "      <td>fail</td>\n",
       "      <td>The model's response does not accurately addre...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What was the dosage of elderberry extract cons...</td>\n",
       "      <td>['Subjects and study design. The study protoco...</td>\n",
       "      <td>The study participants consumed 12 g of elderb...</td>\n",
       "      <td>Bioactivity Researcher (Bi√≥logo)</td>\n",
       "      <td>PERFECT_GRAMMAR</td>\n",
       "      <td>SHORT</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "      <td>The study participants consumed 12 grams of el...</td>\n",
       "      <td>pass</td>\n",
       "      <td>The model's response contains all the key info...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Que es peonidin y de donde viene en los metodo...</td>\n",
       "      <td>['MATERIALS AND METHODS\\n\\n Chemicals and mate...</td>\n",
       "      <td>Peonidin es uno de los seis compuestos que se ...</td>\n",
       "      <td>First Time Analyst (Principiante)</td>\n",
       "      <td>POOR_GRAMMAR</td>\n",
       "      <td>LONG</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "      <td>**Peonidina** es un antociano, un tipo de pigm...</td>\n",
       "      <td>fail</td>\n",
       "      <td>La respuesta del modelo no menciona que la peo...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the significance of sample preparation...</td>\n",
       "      <td>['Human Nutrition and Metabolism\\n\\nAbsorption...</td>\n",
       "      <td>Sample preparation is crucial in the study of ...</td>\n",
       "      <td>Bioactivity Researcher (Bi√≥logo)</td>\n",
       "      <td>PERFECT_GRAMMAR</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "      <td>Sample preparation is a crucial step in the st...</td>\n",
       "      <td>fail</td>\n",
       "      <td>The model's response contains detailed informa...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How do the antioxidant capacities of anthocyan...</td>\n",
       "      <td>['KEY WORDS:\\n\\nanthocyanin\\n\\nmetabolite\\n\\ne...</td>\n",
       "      <td>The antioxidant capacities of anthocyanins (AC...</td>\n",
       "      <td>First Time Analyst (Principiante)</td>\n",
       "      <td>PERFECT_GRAMMAR</td>\n",
       "      <td>LONG</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "      <td>The antioxidant capacities of anthocyanins con...</td>\n",
       "      <td>pass</td>\n",
       "      <td>La respuesta del modelo contiene informaci√≥n c...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What are the key components of the MATERIALS A...</td>\n",
       "      <td>['Human Nutrition and Metabolism\\n\\nAbsorption...</td>\n",
       "      <td>The MATERIALS AND METHODS section details the ...</td>\n",
       "      <td>Bioactivity Researcher (Bi√≥logo)</td>\n",
       "      <td>WEB_SEARCH_LIKE</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "      <td>The **MATERIALS AND METHODS** section in the s...</td>\n",
       "      <td>pass</td>\n",
       "      <td>The model's response contains detailed informa...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What is the focus of the study on anthocyanins...</td>\n",
       "      <td>['Human Nutrition and Metabolism\\n\\n Absorptio...</td>\n",
       "      <td>The study focuses on the absorption and metabo...</td>\n",
       "      <td>Experienced Chemist (Experto)</td>\n",
       "      <td>WEB_SEARCH_LIKE</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "      <td>The study on anthocyanins (ACN) focuses on the...</td>\n",
       "      <td>fail</td>\n",
       "      <td>The model response provides detailed informati...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What happen with elderberry extract in study?</td>\n",
       "      <td>['ABSTRACT\\n\\nThe absorption and metabolism of...</td>\n",
       "      <td>In the study, four elderly women were given 12...</td>\n",
       "      <td>Bioactivity Researcher (Bi√≥logo)</td>\n",
       "      <td>POOR_GRAMMAR</td>\n",
       "      <td>SHORT</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "      <td>In studies involving elderberry extract, subje...</td>\n",
       "      <td>fail</td>\n",
       "      <td>The model's response contains key information ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wht is the absorption and metabolism of anthoc...</td>\n",
       "      <td>['Human Nutrition and Metabolism\\n\\nAbsorption...</td>\n",
       "      <td>The absorption and metabolism of anthocyanins ...</td>\n",
       "      <td>Experienced Chemist (Experto)</td>\n",
       "      <td>MISSPELLED</td>\n",
       "      <td>LONG</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "      <td>In a study examining the absorption and metabo...</td>\n",
       "      <td>pass</td>\n",
       "      <td>La respuesta del modelo contiene la informaci√≥...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How do chemicals and materials play a role in ...</td>\n",
       "      <td>['Human Nutrition and Metabolism\\n\\nAbsorption...</td>\n",
       "      <td>In the study, chemicals and materials such as ...</td>\n",
       "      <td>First Time Analyst (Principiante)</td>\n",
       "      <td>PERFECT_GRAMMAR</td>\n",
       "      <td>LONG</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "      <td>In studies examining the absorption and metabo...</td>\n",
       "      <td>pass</td>\n",
       "      <td>The model's response contains detailed informa...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_input  \\\n",
       "0                     What is Blueberry study about?   \n",
       "1  What was the dosage of elderberry extract cons...   \n",
       "2  Que es peonidin y de donde viene en los metodo...   \n",
       "3  What is the significance of sample preparation...   \n",
       "4  How do the antioxidant capacities of anthocyan...   \n",
       "5  What are the key components of the MATERIALS A...   \n",
       "6  What is the focus of the study on anthocyanins...   \n",
       "7      What happen with elderberry extract in study?   \n",
       "8  Wht is the absorption and metabolism of anthoc...   \n",
       "9  How do chemicals and materials play a role in ...   \n",
       "\n",
       "                                  reference_contexts  \\\n",
       "0  ['Human Nutrition and Metabolism\\n\\nAbsorption...   \n",
       "1  ['Subjects and study design. The study protoco...   \n",
       "2  ['MATERIALS AND METHODS\\n\\n Chemicals and mate...   \n",
       "3  ['Human Nutrition and Metabolism\\n\\nAbsorption...   \n",
       "4  ['KEY WORDS:\\n\\nanthocyanin\\n\\nmetabolite\\n\\ne...   \n",
       "5  ['Human Nutrition and Metabolism\\n\\nAbsorption...   \n",
       "6  ['Human Nutrition and Metabolism\\n\\n Absorptio...   \n",
       "7  ['ABSTRACT\\n\\nThe absorption and metabolism of...   \n",
       "8  ['Human Nutrition and Metabolism\\n\\nAbsorption...   \n",
       "9  ['Human Nutrition and Metabolism\\n\\nAbsorption...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  The Blueberry study investigates the absorptio...   \n",
       "1  The study participants consumed 12 g of elderb...   \n",
       "2  Peonidin es uno de los seis compuestos que se ...   \n",
       "3  Sample preparation is crucial in the study of ...   \n",
       "4  The antioxidant capacities of anthocyanins (AC...   \n",
       "5  The MATERIALS AND METHODS section details the ...   \n",
       "6  The study focuses on the absorption and metabo...   \n",
       "7  In the study, four elderly women were given 12...   \n",
       "8  The absorption and metabolism of anthocyanins ...   \n",
       "9  In the study, chemicals and materials such as ...   \n",
       "\n",
       "                        persona_name      query_style query_length  \\\n",
       "0  First Time Analyst (Principiante)     POOR_GRAMMAR        SHORT   \n",
       "1   Bioactivity Researcher (Bi√≥logo)  PERFECT_GRAMMAR        SHORT   \n",
       "2  First Time Analyst (Principiante)     POOR_GRAMMAR         LONG   \n",
       "3   Bioactivity Researcher (Bi√≥logo)  PERFECT_GRAMMAR       MEDIUM   \n",
       "4  First Time Analyst (Principiante)  PERFECT_GRAMMAR         LONG   \n",
       "5   Bioactivity Researcher (Bi√≥logo)  WEB_SEARCH_LIKE       MEDIUM   \n",
       "6      Experienced Chemist (Experto)  WEB_SEARCH_LIKE       MEDIUM   \n",
       "7   Bioactivity Researcher (Bi√≥logo)     POOR_GRAMMAR        SHORT   \n",
       "8      Experienced Chemist (Experto)       MISSPELLED         LONG   \n",
       "9  First Time Analyst (Principiante)  PERFECT_GRAMMAR         LONG   \n",
       "\n",
       "                        synthesizer_name  \\\n",
       "0  single_hop_specific_query_synthesizer   \n",
       "1  single_hop_specific_query_synthesizer   \n",
       "2  single_hop_specific_query_synthesizer   \n",
       "3  single_hop_specific_query_synthesizer   \n",
       "4  single_hop_specific_query_synthesizer   \n",
       "5  single_hop_specific_query_synthesizer   \n",
       "6  single_hop_specific_query_synthesizer   \n",
       "7  single_hop_specific_query_synthesizer   \n",
       "8  single_hop_specific_query_synthesizer   \n",
       "9  single_hop_specific_query_synthesizer   \n",
       "\n",
       "                                      model_response correctness_score  \\\n",
       "0  The Blueberry study refers to a research proje...              fail   \n",
       "1  The study participants consumed 12 grams of el...              pass   \n",
       "2  **Peonidina** es un antociano, un tipo de pigm...              fail   \n",
       "3  Sample preparation is a crucial step in the st...              fail   \n",
       "4  The antioxidant capacities of anthocyanins con...              pass   \n",
       "5  The **MATERIALS AND METHODS** section in the s...              pass   \n",
       "6  The study on anthocyanins (ACN) focuses on the...              fail   \n",
       "7  In studies involving elderberry extract, subje...              fail   \n",
       "8  In a study examining the absorption and metabo...              pass   \n",
       "9  In studies examining the absorption and metabo...              pass   \n",
       "\n",
       "                                  correctness_reason retrieved_documents  \n",
       "0  The model's response does not accurately addre...                  []  \n",
       "1  The model's response contains all the key info...                  []  \n",
       "2  La respuesta del modelo no menciona que la peo...                  []  \n",
       "3  The model's response contains detailed informa...                  []  \n",
       "4  La respuesta del modelo contiene informaci√≥n c...                  []  \n",
       "5  The model's response contains detailed informa...                  []  \n",
       "6  The model response provides detailed informati...                  []  \n",
       "7  The model's response contains key information ...                  []  \n",
       "8  La respuesta del modelo contiene la informaci√≥...                  []  \n",
       "9  The model's response contains detailed informa...                  []  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostrar resultados detallados\n",
    "print(\"\\nResultados detallados:\")\n",
    "pd.DataFrame(results_agentic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dbf4fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
